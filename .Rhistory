group_by(newspaper_name) %>%
summarise(count = n())
tolnay_ms <-  al_ga_ms_tolnay_back %>%
filter(lynch_state == "MS" & year < 1929 & year >= 1880 & status == "Lynching")
new_mississippi_coverage %>%
filter(in_state == "Y") %>%
group_by(year) %>%
summarise(count = n()) %>%
arrange(year)
new_mississippi_coverage %>%
filter(in_state == "Y") %>%
group_by(year) %>%
summarise(count = n()) %>%
arrange(year)
new_mississippi_coverage %>%
filter(in_state == "N") %>%
group_by(year) %>%
summarise(count = n()) %>%
arrange(year)
tolnay_ms <-  al_ga_ms_tolnay_back %>%
filter(lynch_state == "MS" & year < 1929 & year >= 1880 & status == "Lynching")
tolnay_ms %>%
group_by(decade) %>%
summarise(count = n()) %>%
arrange(desc(count))
new_mississippi_coverage
tolnay_ms %>%
group_by(decade) %>%
summarise(count = n()) %>%
arrange(desc(count))
new_mississippi_coverage %>%
group_by(decade) %>%
summarise(count = n()) %>%
arrange(desc(decade))
tolnay_ms %>%
group_by(decade) %>%
summarise(count = n()) %>%
arrange(desc(decade))
tolnay_ms %>%
count()
new_mississippi_coverage %>%
group_by(decade) %>%
summarise(count = n()) %>%
arrange(desc(decade))
tolnay_ms <-  al_ga_ms_tolnay_back %>%
filter(lynch_state == "MS" & year < 1929 & year >= 1880 & status == "Lynching")
tolnay_ms %>%
count()
tolnay_georgia %>%
count()
tolnay_ms %>%
count()
new_mississippi_coverage %>%
count()
tolnay_georgia %>%
filter(in_state == "Y") %>%
count()
new_mississippi_coverage %>%
filter(in_state == "Y") %>%
count()
new_mississippi_coverage %>%
filter(in_state == "N") %>%
group_by(newspaper_name) %>%
summarise(count = n())
new_mississippi_coverage %>%
filter(in_state == "N") %>%
group_by(newspaper_name) %>%
summarise(count = n())
new_mississippi_coverage %>%
filter(in_state == "N") %>%
group_by(newspaper_name) %>%
summarise(count = n())
new_mississippi_coverage %>%
filter(in_state == "Y") %>%
group_by(newspaper_name) %>%
summarise(count = n())
new_mississippi_coverage %>%
filter(newspaper_name == "Oxford eagle.")
tolnay_beck %>%
filter(decade == 1890 | decade == 1910)
tolnay_ms %>%
filter(decade == 1890 | decade == 1910)
new_mississippi_coverage %>%
filter(newspaper_name == "Macon Beacon.")
new_mississippi_coverage %>%
filter(newspaper_name == "Macon beacon.")
new_mississippi_coverage %>%
filter(newspaper_name == "Macon beacon")
tolnay_ms %>%
filter(decade == 1890)
# load libraries
library(dplyr)
library(ggplot2)
library(tidyverse)
## total ticket data set
df <- read_csv('citationsissued.csv')
View(df)
df<- df[,1:5]
summary(df)
n_distinct(df$Location)
locations <- as.data.frame(table(df$Location))
df<- df[,1:5]
df<- df[,1:5]
summary(df)
n_distinct(df$Location)
locations <- as.data.frame(table(df$Location))
locations
locations %>%
group_by(Var1) %>%
summarise(sum = Freq)
sum(locations$Freq)
locations %>%
group_by(Var1) %>%
summarise(sum = Freq)
locations %>%
summarise(sum = Freq)
df<- df[,1:5]
summary(df)
n_distinct(df$Location)
locations <- as.data.frame(table(df$Location))
# Victoria finding sum of all citations in Union Lane Garage and the  using that to find the % of citations that happen in Union Lane Garage
sum(locations$Freq)
locations
locations %>%
filter(Var1 == "Union Lane Garage") %>%
summarise(sum(Freq))
locations %>%
count(Freq)
locations %>%
sum(Freq)
locations
locations %>%
sum(Freq)
sum(locations$Freq)
(3624/43226)*100
sum(locations$Freq)
df
df %>%
distinct(`Base Amount`) %>%
group_by(`Base Amount`) %>%
summarise(pct = (amounts/sum(amounts))*100)
df %>%
distinct(`Base Amount`) %>%
group_by(`Base Amount`) %>%
summarise(pct = (`Base Amount`/sum(`Base Amount`))*100)
hic_frame <- df %>%
distinct(`Base Amount`)
hic_frame
n_distinct(df$Base.Amount)
summary(df)
df
n_distinct(df$Base.Amount)
amounts <- table(df$Base.Amount)
amounts <- table(df$Base.Amount)
percents<- (amounts/sum(amounts))*100
df <- df %>%
clean_names()
library(janitor)
df <- df %>%
clean_names()
df
n_distinct(df$base_amount)
amounts <- as.data.frame(table(df$base_amount))
View(amounts)
amounts %>%
group_by(amounts) %>%
summarise(sum(Freq))
amounts
amounts %>%
group_by(Var1) %>%
summarise(sum(Freq))
(22084/43227)*100
df %>%
group_by(violation) %>%
summarise(count = n())
df %>%
filter(base_amount == 85)
df %>%
filter(base_amount == 85) %>%
group_by(violation) %>%
summarise(count = n())
df
(15138/43227)*100
df %>%
filter(base_amount == 85) %>%
group_by(violation) %>%
summarise(count = n())
(15138/43227)*100
df2 <- read_csv('citationappeals.csv')
View(df2)
View(df2)
n_distinct(df2$cit_ticket_number)
df2 <- read_csv('citationappeals.csv')
n_distinct(df2$cit_ticket_number)
df2 %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
df2 <- read_csv('citationappeals.csv')
View(df2)
View(df2)
df2 <- read_csv('citationappeals.csv')
View(df2)
n_distinct(df)
df
View(df)
n_distinct(df2$cit_ticket_number)
df2
View(df2)
df2
n_distinct(df$base_amount)
n_distinct(df)
n_distinct(df$Location)
9728/43227
9728/43227
n_distinct(df2$cit_ticket_number)
df3 <- n_distinct(df2$cit_ticket_number)
df2 <- read_csv('citationappeals.csv')
n_distinct(df2$cit_ticket_number)
df2 %>%
filter(appl_judgement_display_name == "Cancelled")
df2 %>%
filter(appl_judgement_display_name == "Cancelled") %>%
group_by(appl_judgement_comments) %>%
summarise(count = n())
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
df2 <- read_csv('citationappeals.csv')
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(appl_judgement_display_name) %>%
summarise(count = n())
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n())
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
df2 %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
df2 <- read_csv('citationappeals.csv')
df2 <- read_csv('citationappeals.csv')
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
6662/43227
df2 <- read_csv('citationappeals.csv')
View(df2)
6662/9728
df2=df2[grepl("Citation Voided|Fine Reduction|Warning", df2$appl_judgement_display_name)]
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
fuck <- df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
write_csv(fuck, "fuck.csv")
fuck
9728/43227
df2
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
View(fuck)
6664/9728
df2
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
View(df2)
df2=df2[grepl("Second", df2$appl_judgement_display_name),]
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
df2
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
df2 %>%
group_by(appl_judgement_display_name) %>%
summarise(count = n())
# total appeals
df2 <- read_csv('citationappeals.csv')
n_distinct(df2$cit_ticket_number)
# total number of appears is 9728 -- divide by total number of citations to get how many citations got appealed
9728/43227
#NEW FROM BRIDGET what percent of parking tickets are appealed
# 8427/43227
#NEW FROM BRIDGET what percent of parking tickets  resulted in a voided citation, a fine reduction, or the citation was dropped to a warning?
df2 %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
fuck <- df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
write_csv(fuck, "fuck.csv")
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
# 6,215
df2 %>%
filter(appl_judgement_display_name == "Cancelled") %>%
group_by(appl_judgement_comments) %>%
summarise(count = n())
# 449
# 6664
df2=df2[grepl("Citation Voided|Fine Reduction|Warning", df2$appl_judgement_display_name)]
# total appeals
df2 <- read_csv('citationappeals.csv')
n_distinct(df2$cit_ticket_number)
# total number of appears is 9728 -- divide by total number of citations to get how many citations got appealed
9728/43227
#NEW FROM BRIDGET what percent of parking tickets are appealed
# 8427/43227
#NEW FROM BRIDGET what percent of parking tickets  resulted in a voided citation, a fine reduction, or the citation was dropped to a warning?
df2 %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
fuck <- df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
write_csv(fuck, "fuck.csv")
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
# 6,215
df2 %>%
filter(appl_judgement_display_name == "Cancelled") %>%
group_by(appl_judgement_comments) %>%
summarise(count = n())
# 449
# 6664
# total number of successful appeals divided by the total number of appeals generally
6664/9728
# results in 68 percent
# BRIDGET HULLABALLOO
# what percent of appeals are accepted? 73.727%
# 8,427 completed appeals and 6,123 appeals resulted in a voided citation, a fine reduction, or the citation was dropped to a warming
(6213/8427)*100
# what percent of appeals resulted in a fine reduction? 41.189%
(3471/8427)*100
# what percent of appeals resulted in a void? 32.526%
(2741/8427)*100
41.18904 + 32.5264
# what percent of appeals resulted in a warning? 1%<
(7/8427)*100
# what percent of second appeals get accepted? 10.909%
# there are 55 completed second appeals, 3 resulted in a voided citation and three resulted in a fine reduction
6/55
# what percent of appeals get accept by lot? The parking ticket appeal data does not have the lot variable
# how many appeals are there per lot? The parking ticket appeal data does not have the lot variable
df2=df2[grepl("2nd", df2$appl_judgement_display_name),]
df2 %>%
group_by(appl_judgement_display_name) %>%
summarise(count = n())
df2 %>%
group_by(appl_judgement_display_name) %>%
summarise(count = n())
# total appeals
df2 <- read_csv('citationappeals.csv')
n_distinct(df2$cit_ticket_number)
# total number of appears is 9728 -- divide by total number of citations to get how many citations got appealed
9728/43227
#NEW FROM BRIDGET what percent of parking tickets are appealed
# 8427/43227
#NEW FROM BRIDGET what percent of parking tickets  resulted in a voided citation, a fine reduction, or the citation was dropped to a warning?
df2 %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
fuck <- df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning")
write_csv(fuck, "fuck.csv")
df2 %>%
filter(appl_judgement_display_name == "Citation Voided" | appl_judgement_display_name == "Fine Reduction" | appl_judgement_display_name == "Warning") %>%
group_by(cit_ticket_number) %>%
summarise(count = n()) %>%
arrange(desc(count))
# 6,215
df2 %>%
filter(appl_judgement_display_name == "Cancelled") %>%
group_by(appl_judgement_comments) %>%
summarise(count = n())
# 449
# 6664
# total number of successful appeals divided by the total number of appeals generally
6664/9728
# results in 68 percent
# BRIDGET HULLABALLOO
# what percent of appeals are accepted? 73.727%
# 8,427 completed appeals and 6,123 appeals resulted in a voided citation, a fine reduction, or the citation was dropped to a warming
(6213/8427)*100
# what percent of appeals resulted in a fine reduction? 41.189%
(3471/8427)*100
# what percent of appeals resulted in a void? 32.526%
(2741/8427)*100
41.18904 + 32.5264
# what percent of appeals resulted in a warning? 1%<
(7/8427)*100
# what percent of second appeals get accepted? 10.909%
# there are 55 completed second appeals, 3 resulted in a voided citation and three resulted in a fine reduction
6/55
# what percent of appeals get accept by lot? The parking ticket appeal data does not have the lot variable
# how many appeals are there per lot? The parking ticket appeal data does not have the lot variable
df2 %>%
group_by(appl_judgement_display_name) %>%
summarise(count = n())
df3=df2[grepl("2nd", df2$appl_judgement_display_name),]
View(df3)
#install.packages("here")
#here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#install.packages("geosphere")
library(geosphere)
library(janitor)
#install.packages('scales')
library(scales)
states_df
lynch_updated
lynch_updated %>%
filter(state_lynch == "GA" & year == 1903)
new_georgia_coverage
new_georgia_coverage %>%
filter(state_lynch == "GA" & year == 1903)
lynch_updated %>%
filter(state_lynch == "GA" & year == 1903)
new_georgia_coverage %>%
filter(year == 1903)
lynch_updated %>%
filter(state_lynch == "GA" & year == 1903)
new_georgia_coverage %>%
filter(year == 1903)
tolnay_georgia %>%
filter(year == 1889 | year == 1890 | year == 1891)
tolnay_georgia %>%
filter(lynch_county == "Chatham")
tolnay_georgia %>%
filter(year == 1896)
lynch_updated %>%
filter(state_lynch == "GA" & year == 1896)
new_georgia_coverage %>%
filter(newspaper_name == "The morning news")
new_georgia_coverage %>%
filter(newspaper_name == "The morning news" & year == 1896)
new_georgia_coverage
new_georgia_coverage %>%
filter(newspaper_name == "The morning news" | newspaper_name == "Savannah morning news" | newspaper_name == "The Savannah morning news." & year == 1896)
new_georgia_coverage %>%
filter(newspaper_name == "The morning news" | newspaper_name == "Savannah morning news" | newspaper_name == "The Savannah morning news.") %>%
filter(year == 1896)
new_georgia_coverage %>%
filter(year == 1896)
new_georgia_coverage %>%
filter(year == 1903)
tolnay_georgia %>%
filter(year == 1903)
new_mississippi_coverage %>%
filter(newspaper_name == "Warren sheaf")
new_mississippi_coverage <- lynch_updated %>%
filter(newspaper_state_code == "MS") %>%
select(decade, year, newspaper_name, newspaper_state_code, state_lynch, in_state, border, total_words)
new_mississippi_coverage %>%
filter(newspaper_name == "Warren sheaf")
setwd("~/Documents/GitHub/Jour389L")
#install.packages("here")
#here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#install.packages("geosphere")
library(geosphere)
library(janitor)
#install.packages('scales')
library(scales)
bigram_lynch_1890s <- read.csv("output/1890s_lynch_bigram_count.csv")
#install.packages("here")
#here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#install.packages("geosphere")
library(geosphere)
library(janitor)
#install.packages('scales')
library(scales)
bigram_lynch_1890s <- read.csv("output/1890s_lynch_bigram_count.csv")
setwd("~/Documents/GitHub/Jour389L")
ga_tolnay_news
new_mississippi_coverage
bigram_lynch_1890s <- read.csv("output/1890s_lynch_bigram_count.csv")
bigram_lynch_1890s <- read_csv("output/1890s_lynch_bigram_count.csv")
setwd("~/Documents/GitHub/Jour389L")
bigram_lynch_1890s <- read_csv("output/1890s_lynch_bigram_count.csv")
