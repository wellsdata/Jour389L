---
title: "Geographic Analysis"
author: "Khushboo Rathore"
date: "2023-09-20"
output: html_document
---

#Wells comments on this fine data analysis

```{r}
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("tigris")
#install.packages("zoo")
library(tigris)
library(stringr)
library(janitor)
library(zoo)

```
# Analysis
```{r}
lynch_geocoded_9.16 <- read.csv("../data/lynch_geocoded_9.16.csv")

```

## Regional classification for newspaper

```{r}
#Classification based on https://www.census.gov/programs-surveys/economic-census/guidance-geographies/levels.html#par_textimage_34
lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(Newspaper_Region=Newspaper_State) %>% 
  mutate(Newspaper_Region = case_when(Newspaper_State=="South Carolina" ~ "South",
                           Newspaper_State=="Texas" ~ "South",
                            Newspaper_State=="Louisiana" ~ "South",
                            Newspaper_State=="Tennessee" ~ "South",
                            Newspaper_State=="Mississippi" ~ "South",
                            Newspaper_State=="Arkansas" ~ "South",
                            Newspaper_State=="Alabama" ~ "South",
                            Newspaper_State=="Georgia" ~ "South",
                            Newspaper_State=="Virginia" ~ "South",
                            Newspaper_State=="Florida" ~ "South",
                            Newspaper_State=="North Carolina" ~ "South",
                            Newspaper_State=="Maryland" ~ "South",
                            Newspaper_State=="Delaware" ~ "South",
                            Newspaper_State=="West Virginia" ~ "South",
                            Newspaper_State=="Kentucky" ~ "South",
                            Newspaper_State=="Missouri" ~ "Midwest",
                            Newspaper_State=="Maine" ~ "Northeast",
                            Newspaper_State=="New York" ~ "Northeast",
                            Newspaper_State=="New Hampshire" ~ "Northeast",
                            Newspaper_State=="Vermont" ~ "Northeast",
                            Newspaper_State=="Massachusetts" ~ "Northeast",
                            Newspaper_State=="Connecticut" ~ "Northeast",
                            Newspaper_State=="Rhode Island" ~ "Northeast",
                            Newspaper_State=="Pennsylvania" ~ "Northeast",
                            Newspaper_State=="New Jersey" ~ "Northeast",
                            Newspaper_State=="Ohio" ~ "Midwest",
                            Newspaper_State=="Indiana" ~ "Midwest",
                            Newspaper_State=="Kansas" ~ "Midwest",
                            Newspaper_State=="Michigan" ~ "Midwest",
                             Newspaper_State=="Wisconsin" ~ "Midwest",
                             Newspaper_State=="Minnesota" ~ "Midwest",
                             Newspaper_State=="Iowa" ~ "Midwest",
                             Newspaper_State=="California" ~ "West",
                             Newspaper_State=="Nevada" ~ "West",
                             Newspaper_State=="Oregon" ~ "West",
                            Newspaper_State=="Illinois" ~ "Midwest",
                            Newspaper_State=="Nebraska" ~ "Midwest",
                            Newspaper_State=="Colorado" ~ "West",
                            Newspaper_State=="North Dakota" ~ "Midwest",
                            Newspaper_State=="South Dakota" ~ "Midwest",
                            Newspaper_State=="Montana" ~ "West",
                            Newspaper_State=="Washington" ~ "West",
                            Newspaper_State=="Idaho" ~ "West",
                            Newspaper_State=="Wyoming" ~ "West",
                            Newspaper_State=="Utah" ~ "West",
                            Newspaper_State=="Oklahoma" ~ "South",
                            Newspaper_State=="New Mexico" ~ "West",
                            Newspaper_State=="Arizona" ~ "West",
                            Newspaper_State=="Alaska" ~ "West",
                            Newspaper_State=="Hawaii" ~ "West",
                            Newspaper_State=="District of Columbia" ~ "South",
                            Newspaper_State=="Virgin Islands" ~ "Misc",
                                                     TRUE~Newspaper_State))

#delete old version
# lynch_geocoded_9.27 <- subset(lynch_geocoded_9.27, select =-Newspaper_Region2)

#write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```

### Border Designation
```{r}
lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(Border = case_when(Newspaper_State=="Maryland" ~ "Border",
                            Newspaper_State=="Delaware" ~ "Border",
                            Newspaper_State=="West Virginia" ~ "Border",
                            Newspaper_State=="Kentucky" ~ "Border",
                            Newspaper_State=="Missouri" ~ "Border",
                               .default = "Not_Border"))

# write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```

# WEEK ONE
```{r}
## Pct of Newspapers in state vs out of state
 lynch_geocoded_9.16 %>% 
  count(in_state) %>% 
  mutate(pct = round(n/3292,2))


# in_state
# N	3068	0.93		
# Y	223	0.07	

summary(lynch_geocoded_9.16$miles)
#Newspapers, on average, were 878 miles away from a lynching event during the whole time period

duplicated_entries <- lynch_geocoded_9.16 %>% 
  group_by(file_id) %>% 
  count(lynch_address) %>% 
  filter(n > 1)

# Repetitions: 
write_sheet(duplicated_entries, "https://docs.google.com/spreadsheets/d/1mt-K372GEtjE_v0qeiX-57MlnAD-9tT5f4AZr4NxZnY/edit#gid=0")


```

## In State v Out of State by Decade
```{r}

x <- lynch_geocoded_9.16 %>% 
  select(decade, miles, in_state) %>% 
  group_by(decade) %>% 
  count(in_state)

  ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
    geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
       subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
       caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
       y="Count of articles",
       x="")
  
cleaned_articles <- lynch_geocoded_9.16 %>% 
  distinct(file_id, lynch_address, .keep_all = TRUE) %>% 
  mutate(location = case_when(
    newspaper_state_code == state_lynch ~ "in_state",
    TRUE~"out_of_state"
  ))
  
decade_data <- cleaned_articles %>% 
  group_by(decade, location) %>% 
  count(.) %>% 
  pivot_wider(names_from = location, values_from = n) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>% 
  mutate(sum_articles = out_of_state + in_state) %>% 
  mutate(percent_oos = round(out_of_state/sum_articles*100, 2)) %>% 
  mutate(percent_is = round(in_state/sum_articles*100, 2))

write_sheet(decade_data, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0")

state_groupings <- cleaned_articles %>%
  group_by(newspaper_state_code, location) %>% 
  count(.) %>% 
  pivot_wider(names_from = location, values_from = n) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>% 
  mutate(sum_articles = out_of_state + in_state) %>% 
  mutate(percent_oos = round(out_of_state/sum_articles*100, 2)) %>% 
  mutate(percent_is = round(in_state/sum_articles*100, 2))

write_sheet(state_groupings, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0")

```


# WEEK TWO
```{r}
# Analyze broader dataset of all lynchings by decade and state and region. Want to see if our sample of lynchings by state is skewed. Total and percentage by state. Group in Regional categories. Next, calculate baseline totals of the newspapers in the states. 

tolnay_beck <- read_csv("../data/Bailey_Beck_lynching_list_8_1_2022.csv") %>% 
  as.data.frame()

tolnay_beck <- janitor::clean_names(tolnay_beck)

#Import failed due to the link. Please assign links to Github
# lynch_article_data <- read_csv("~/Desktop/GitHub/Jour389L/data/lynch_geocoded_9.27.csv")

lynch_article_data <- read_csv("../data/lynch_geocoded_9.27.csv")

# Basic filter to distinct lynchings
# RSW comment - distinct line drops 700+ cases. I think you are trying to get a df with single instances of a lynching incident to compare apples-apples to tolnay-beck, right? 
#Need to improve the distinct line since year is too broad. try year-month


lynch_data <- lynch_article_data %>% 
  mutate(date = as.Date(date, "%m/%d/%Y")) %>% 
  distinct(year, lynch_address, .keep_all = TRUE)

#RSW - creating yearmo, we lose just 437 cases this way
lynch_data1 <- lynch_article_data %>% 
  mutate(date = as.Date(date, "%m/%d/%Y")) %>% 
  mutate(yearmo = zoo::as.yearmon(date)) %>% 
  distinct(yearmo, lynch_address, .keep_all=TRUE)         

x <- lynch_data1 %>% 
  count(file_id) %>% 
  arrange(desc(n))


#RSW: Interesting call on the filter, it removes bystanders
beck_lynchings <- tolnay_beck %>% 
  filter(!str_detect(status, "death"))

```

## Analysis by State
```{r}
beck_by_state <- beck_lynchings %>%
  group_by(lynch_state) %>% 
  count(.) %>% 
  rename(state_lynch = lynch_state) %>% 
  rename(beck_count = n) %>% 
  mutate(percent_lynchings_beck = round(beck_count/nrow(beck_lynchings)*100,2))
    

# Percent of all lynchings that are in each state
lynch_by_state <- lynch_data %>% 
  group_by(state_lynch) %>% 
  count(.) %>% 
  rename(input_count = n) %>% 
  mutate(percent_lynchings_input = round(input_count/nrow(lynch_data)*100,2))

#RSW
lynch_by_state1 <- lynch_data1 %>% 
  group_by(state_lynch) %>% 
  count(.) %>% 
  rename(input_count = n) %>% 
  mutate(percent_lynchings_input = round(input_count/nrow(lynch_data)*100,2))

state_lynchings_compare <- lynch_by_state %>% 
  left_join(beck_by_state, by = "state_lynch") %>% 
  mutate(beck_input_dif = percent_lynchings_beck-percent_lynchings_input)

#RSW
state1_lynchings_compare <- lynch_by_state1 %>% 
  left_join(beck_by_state, by = "state_lynch") %>% 
  mutate(beck_input_dif = percent_lynchings_beck-percent_lynchings_input)

write_sheet(state_lynchings_compare, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "state_lynchings_compare")
```

## Analysis by Region
```{r}
beck_region_coded <- beck_lynchings %>%
  select(status, lynch_state) %>% 
  mutate(lynch_region = case_when(
    str_detect(lynch_state, "SC|TX|LA|TN|MS|AR|AL|GA|VA|FL|NC") ~ "south",
    str_detect(lynch_state, "MD|DE|WV|KY|MO") ~ "border",
    str_detect(lynch_state, "ME|NY|NH|VT|MA|CT|RI|PA|NJ|OH|IN|KS|MI|WI|MN|IA|CA|NV|OR|IL") ~ "north",
    str_detect(lynch_state, "NE|CO|ND|SD|MT|WA|ID|WY|UT|OK|NM|AZ|AK|HI") ~ "misc",
    TRUE~lynch_state
    )) 

lynch_cleaned <- lynch_data %>% 
  clean_names() %>% 
  mutate(newspaper_region = tolower(newspaper_region))

lynch_by_region <- lynch_cleaned %>% 
  group_by(newspaper_region) %>% 
  count(.) %>% 
  rename(input_count = n) %>% 
  mutate(percent_lynchings_input = round(input_count/nrow(lynch_data)*100,2))

beck_by_region <- beck_region_coded %>% 
  group_by(lynch_region) %>% 
  count(.) %>% 
  rename(beck_count = n) %>% 
  mutate(percent_lynchings_beck = round(beck_count/nrow(beck_region_coded)*100,2))

regional_comparison <- lynch_by_region %>% 
  left_join(beck_by_region, by = c("newspaper_region" = "lynch_region")) %>% 
    mutate(beck_input_dif = percent_lynchings_beck-percent_lynchings_input)

write_sheet(regional_comparison, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "regional_comparison")
```
## Newspapers in States & Regions
```{r}
newspaper_list <- lynch_article_data %>% 
  clean_names() %>% 
  distinct(newspaper_name, news_address, .keep_all = TRUE)

paper_count_by_state <- newspaper_list %>% 
  group_by(newspaper_state) %>% 
  count(.) %>% 
  rename(count_papers = n) %>% 
  mutate(percent_papers = round(count_papers/nrow(newspaper_list)*100,2))

write_sheet(paper_count_by_state, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "count_newspapers_in_states")

paper_count_by_region <- newspaper_list %>% 
  group_by(newspaper_region) %>% 
  count(.) %>% 
  rename(count_papers = n) %>% 
  mutate(percent_papers = round(count_papers/nrow(newspaper_list)*100,2))

write_sheet(paper_count_by_region, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "count_newspapers_per_region")
```

```{r}
beck_lynchings %>% 
  group_by(status) %>% 
  count(.) 
```

# WEEK THREE
```{r}
tolnay_beck <- read_csv("../data/Bailey_Beck_lynching_list_8_1_2022.csv") %>% 
  as.data.frame()

tolnay_beck <- clean_names(tolnay_beck)

#Import failed due to the link. Please assign links to Github
lynch_article_data <- read_csv("../data/lynch_geocoded_10.8.csv")

# Basic filter to distinct lynchings
# RSW comment - distinct line drops 700+ cases. I think you are trying to get a df with single instances of a lynching incident to compare apples-apples to tolnay-beck, right? 
#Need to improve the distinct line since year is too broad. try year-month

lynch_data <- lynch_article_data %>% 
  mutate(date = as.Date(date, "%m/%d/%Y")) %>% 
  mutate(yearmo = as.yearmon(date)) %>% 
  #distinct(year, lynch_address, .keep_all = TRUE) %>% 
    distinct(yearmo, lynch_address, .keep_all = TRUE) %>% 
  clean_names() %>% 
  mutate(lynch_region = case_when(
    str_detect(state_lynch, "SC|TX|LA|TN|MS|AR|AL|GA|VA|FL|NC|MD|DE|WV|KY|OK|DC")~"South",
    str_detect(state_lynch, "MO|OH|IN|KS|MI|WI|MN|IA|IL|NE|ND|SD")~"Midwest",
    str_detect(state_lynch, "NY|NH|VT|MA|CT|RI|PA|NJ|ME")~"Northeast",
    str_detect(state_lynch, "CA|NV|OR|CO|MT|WA|ID|WY|UT|NM|AZ|AK|HI")~"West",
    TRUE~state_lynch
  )) %>% 
  mutate(lynch_border = case_when(
    str_detect(state_lynch, "MD|DE|WV|KY|MO")~"Border",
    TRUE~"Not_Border"
  ))


#RSW: Interesting call on the filter, it removes bystanders
beck_lynchings <- tolnay_beck %>% 
  filter(!str_detect(status, "death")) %>% 
  mutate(lynch_region = case_when(
    str_detect(lynch_state, "SC|TX|LA|TN|MS|AR|AL|GA|VA|FL|NC|MD|DE|WV|KY|OK|DC")~"South",
    str_detect(lynch_state, "MO|OH|IN|KS|MI|WI|MN|IA|IL|NE|ND|SD")~"Midwest",
    str_detect(lynch_state, "NY|NH|VT|MA|CT|RI|PA|NJ")~"Northeast",
    str_detect(lynch_state, "CA|NV|OR|CO|MT|WA|ID|WY|UT|NM|AZ|AK|HI")~"West",
    TRUE~lynch_state
  )) %>% 
  mutate(lynch_border = case_when(
    str_detect(lynch_state, "MD|DE|WV|KY|MO")~"Border",
    TRUE~"Not_Border"
  ))
  
```

## Region & Border Reclassification and Analysis
```{r}
lynch_by_region_updated <- lynch_data %>% 
  group_by(lynch_region) %>% 
  count(.) %>% 
  rename(lynch_count = n) %>% 
  mutate(lynch_percent = round(lynch_count/nrow(lynch_data)*100,2))
  

beck_region_coded <- beck_lynchings %>%
  select(status, lynch_state, lynch_region, lynch_border)
  

beck_regional <- beck_region_coded %>% 
  group_by(lynch_region) %>% 
  count(.) %>% 
  rename(beck_count = n) %>% 
  mutate(beck_percent = round(beck_count/nrow(beck_region_coded)*100,2))

regional_comparison_updated <- lynch_by_region_updated %>% 
  left_join(beck_regional) %>% 
  mutate(percent_diff = lynch_percent - beck_percent)

write_sheet(regional_comparison_updated, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "oct_nine_regional")

lynch_by_border <- lynch_data %>% 
  group_by(lynch_border) %>% 
  count(.) %>% 
  rename(lynch_count = n) %>% 
  mutate(lynch_percent = round(lynch_count/nrow(lynch_data)*100,2))

beck_border <- beck_region_coded %>% 
  group_by(lynch_border) %>% 
  count(.) %>% 
  rename(beck_count = n) %>% 
  mutate(beck_percent = round(beck_count/nrow(beck_region_coded)*100,2))

border_state_comparison <- lynch_by_border %>% 
  left_join(beck_border) %>% 
  mutate(percent_diff = lynch_percent - beck_percent)

write_sheet(border_state_comparison, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "oct_nine_border")
```

## Updated state comparisons
```{r}
lynch_by_state_updated <- lynch_data %>% 
  clean_names() %>% 
  group_by(state_lynch) %>% 
  count(.) %>% 
  rename(lynch_count = n) %>% 
  rename(lynch_state = state_lynch) %>% 
  mutate(lynch_percent = round(lynch_count/nrow(lynch_data)*100,2))

#code fails on beck_count/nrow(beck_region_coded
# beck_by_state <- beck_lynchings %>% 
#   group_by(lynch_state) %>% 
#   count(.) %>% 
#   rename(beck_count = n) %>% 
#   mutate(beck_percent = round(beck_count/nrow(beck_region_coded)*100,2))

#fixed-rsw
beck_by_state <- beck_lynchings %>% 
  group_by(lynch_state) %>% 
  count(.) %>% 
  rename(beck_count = n) %>% 
  mutate(beck_percent = round(beck_count/nrow(beck_lynchings)*100,2))

state_comparison_updated <- lynch_by_state_updated %>% 
  left_join(beck_by_state) %>% 
 # mutate(percent_diff = lynch_percent - beck_percent)
    mutate(pct_point_diff = lynch_percent - beck_percent)

# write.csv(state_comparison_updated, "/Users/robwells/Code/hcij_lynching_phase_two/narratives/output/state_comparison_updated.csv")

write_sheet(state_comparison_updated, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "oct_nine_state")

```

## Decade Comparisons
```{r}
lynch_by_decade <- lynch_data %>% 
  clean_names() %>% 
  mutate(decade = floor(year/10) * 10) %>% 
  group_by(decade) %>% 
  count(.) %>% 
  rename(lynch_count = n) %>%
  mutate(lynch_percent = round(lynch_count/nrow(lynch_data)*100,2))

#code fails on beck_count/nrow(beck_region_coded
# beck_by_decade <- beck_lynchings %>%
#   mutate(decade = floor(year/10) * 10) %>% 
#   group_by(decade) %>% 
#   count(.) %>% 
#   rename(beck_count = n) %>% 
#   mutate(beck_percent = round(beck_count/nrow(beck_region_coded)*100,2))

#fixed - rsw
beck_by_decade <- beck_lynchings %>%
  mutate(decade = floor(year/10) * 10) %>% 
  group_by(decade) %>% 
  count(.) %>% 
  rename(beck_count = n) %>% 
  mutate(beck_percent = round(beck_count/nrow(beck_lynchings)*100,2))


decade_comparison <- lynch_by_decade %>% 
  full_join(beck_by_decade) %>% 
  #it's percentage point, not percentage difference - rsw
  #  mutate(percent_diff = lynch_percent - beck_percent)
    mutate(pct_point_diff = lynch_percent - beck_percent)

# write.csv(decade_comparison, "/Users/robwells/Code/hcij_lynching_phase_two/narratives/output/decade_comparison.csv")

write_sheet(decade_comparison, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0", sheet = "oct_nine_decades")

```

# CLEAN MAIN INDEX
```{r}
main_index <- read_csv("../data/mainindex.csv")

x <- main_index %>% 
  count(newspaper_state) %>% 
  arrange(desc(n))

clean_main_index <- main_index %>% 
  # Clean out any numbers
  mutate(newspaper_state_clean = str_squish(gsub("[0-9]", "", newspaper_state))) %>% 
  # Clean out any non-letter characters
  mutate(newspaper_state_clean = str_squish(gsub("\\W", "", newspaper_state_clean)))

y <- clean_main_index %>% 
  count(newspaper_state_clean) %>% 
  arrange(desc(n))

#347 categories in the newspaper_states, needs to be cleaned to 50 or so categories in standard two-digit state format, ie. GA for Georgia, CA for California

```

COME BACK TO: MI

Alabama: Ala
Alaska: Alas, Alask
Arizona: Ari, Ariz, ArizT, ATA, Cochise, Marico, Pima, PimaCo, Pin
Arkansas: A, Ark, Arkcurrent, Faulkne
California: Butte, Ca, Cal, C & Grass Valley, Calif, El, ElDora, Placer
Colorado: Ba, Co & Canon City, Col, Colo, Conejo, DeltaCo, Elbert, Logan, Montez, RubyCaGunnisonCountyColo
Connecticut: Co & New Britain, Con, Conn, Litc
Delaware: De, Del, 
Florida: F, Fl, Fla, MarionC
Georgia: Ga
Hawaii: Hawai, HawaiianIsland, HI, Maui
Idaho: I & Silver City, Id, Ida, Idah, Idaho, North
Illinois: Il, Ill
Indiana: I & Bloomington, I & Indianapolis, Ia, Iai, Ind, MarshallCountyInd, Ran
Iowa: Audubo, CedarC, How, Howard, I & Marshalltown, I & Independence, Io, Iow, Maha
Kansas: Allen Cou, K, Ka, Kan, Kansa
Kentucky: Bourbon, Ky Madis
Louisiana: Attak, Bossi, Calcasie, GrantP, L, La, Lna, P, Par, Pari
Maine: Me
Maryland: M & Port Tobacco, M & Leonard Town, Md
Massachusetts
Michigan: LSM, M & Grand Rapids, M & East Saginaw, Mic, Mich
Minnesota: Be, Bemidji, BlueE, Brown, C & Cook County, Goodh, M & Little Falls, M & Fergus Falls, M & Grand Marais, M & Sauk Rapids, Min, Minn, MT, PineCou
Mississippi: Cop, DeSot, Lafayet, Lefl, M & Water Valley, M & Philadelphia, MT, Marshal, Mis, Miss
Missouri: Ada, Audrain, Ch, IronC, Lafa, Missour, Mo (excepting Montana examples), RayC, Salin, ScottC
Montana: M & Stevensville, M & Diamond City, MTM, Philipsburg & Mo, Mo & Great Falls, Mo & Fort Benton, Mont, Montcurrent, MTM
Nebraska: BoxB, Cher, H, N & North Platte, N & Grand Island, Ne & Nemaha City, Ne & Dakota City, Neb, Nebr, Nebras, Nebrask, Nem
Nevada: Ne & Carson City, Ne & Silver City, Nev, NT
New Hampshire
New Jersey: Bu & Mount Holly, N & Perth Amboy, NJ, Penn's Grove & S
New Mexico: Gu, MoraCo, N & Silver City, N & Albuquerque, Ne & Albuquerque, NM, NMT, Rooseve, Socorr
New York: NY
North Carolina: E, Edge, Meck, N & Jacksonville, N & Hillsborough, N & Chapel Hill, NC
North Dakota: Billings, Bott, D, Dakot & Bismarck, Dakota & Pembina, DickeyC, DT, Gr, McLea, N & Valley City, N & Grand Forks, ND, Richl
Ohio: Ashlan, Bro, Hancoc, High, Ho, HolmesCoOOhio, Mahon, Meigs, O (Excepting Oregon), Oh, Ohi, OO, OOh, OOhi, OOhio, Sandus
Oklahoma: Choctaw, CraigC, Indi, India, Indian, IndianT, IndTe, Okla, Oklah, OTO
Oregon: Lin, Lincoln, LinnCo, Morrow, O & Pendleton, Or, Orego
Pennsylvania: Pa
Rhode Island
South Carolina: Claren, SC
South Dakota: Bl, Broo, Brule, Bu & Dakota, Dako, Dakot & Mitchell, S (Excepting NJ), Dakota & Hurley, Dakota & Miller, DayCo, DTS, Haakon, HandCo, Pen, Rober, SD, South
Tennessee: GibsonC, Hardem, McNairy, MorganC
Texas
Utah: CityUt
Vermont: St. Johnsb, Orlean
Virginia: Augus, Highl, 
Washington: Cheha, OT
Washington D.C.: DC
West Virginia
Wisconsin: Ashland, Jeff, Pi, Rusk
Wyoming: Carbo
