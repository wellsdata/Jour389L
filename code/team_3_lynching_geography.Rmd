---
title: "lynching_geography"
output: html_document
date: "2023-09-21"
---

# Wells added new regional classification code below. This is incorporated in the latest version of lynch_geocoded_9.27.csv but I made it available in case you needed it.

```{r setup, include=FALSE}

#install.packages("here")
#here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#install.packages("geosphere")
library(geosphere)
library(janitor)
#install.packages('scales')
library(scales)

```

## Group 3 Week 1 Analysis

## with messy, not fully updated data

Southern coverage vs other regions (north, border)

```{r}

# lynching_data <- read.csv("data/lynch_geocoded_9.16.csv")

lynching_data <- read.csv("../data/lynch_geocoded_10.8.csv")

```

#Wells added:
## Regional classification for newspaper

```{r}
#Classification based on https://www.census.gov/programs-surveys/economic-census/guidance-geographies/levels.html#par_textimage_34
lynch_geocoded_10.8 <- lynch_geocoded_10.8 %>% 
  mutate(Newspaper_Region=Newspaper_State) %>% 
  mutate(Newspaper_Region = case_when(Newspaper_State=="South Carolina" ~ "South",
                           Newspaper_State=="Texas" ~ "South",
                            Newspaper_State=="Louisiana" ~ "South",
                            Newspaper_State=="Tennessee" ~ "South",
                            Newspaper_State=="Mississippi" ~ "South",
                            Newspaper_State=="Arkansas" ~ "South",
                            Newspaper_State=="Alabama" ~ "South",
                            Newspaper_State=="Georgia" ~ "South",
                            Newspaper_State=="Virginia" ~ "South",
                            Newspaper_State=="Florida" ~ "South",
                            Newspaper_State=="North Carolina" ~ "South",
                            Newspaper_State=="Maryland" ~ "South",
                            Newspaper_State=="Delaware" ~ "South",
                            Newspaper_State=="West Virginia" ~ "South",
                            Newspaper_State=="Kentucky" ~ "South",
                            Newspaper_State=="Missouri" ~ "Midwest",
                            Newspaper_State=="Maine" ~ "Northeast",
                            Newspaper_State=="New York" ~ "Northeast",
                            Newspaper_State=="New Hampshire" ~ "Northeast",
                            Newspaper_State=="Vermont" ~ "Northeast",
                            Newspaper_State=="Massachusetts" ~ "Northeast",
                            Newspaper_State=="Connecticut" ~ "Northeast",
                            Newspaper_State=="Rhode Island" ~ "Northeast",
                            Newspaper_State=="Pennsylvania" ~ "Northeast",
                            Newspaper_State=="New Jersey" ~ "Northeast",
                            Newspaper_State=="Ohio" ~ "Midwest",
                            Newspaper_State=="Indiana" ~ "Midwest",
                            Newspaper_State=="Kansas" ~ "Midwest",
                            Newspaper_State=="Michigan" ~ "Midwest",
                             Newspaper_State=="Wisconsin" ~ "Midwest",
                             Newspaper_State=="Minnesota" ~ "Midwest",
                             Newspaper_State=="Iowa" ~ "Midwest",
                             Newspaper_State=="California" ~ "West",
                             Newspaper_State=="Nevada" ~ "West",
                             Newspaper_State=="Oregon" ~ "West",
                            Newspaper_State=="Illinois" ~ "Midwest",
                            Newspaper_State=="Nebraska" ~ "Midwest",
                            Newspaper_State=="Colorado" ~ "West",
                            Newspaper_State=="North Dakota" ~ "Midwest",
                            Newspaper_State=="South Dakota" ~ "Midwest",
                            Newspaper_State=="Montana" ~ "West",
                            Newspaper_State=="Washington" ~ "West",
                            Newspaper_State=="Idaho" ~ "West",
                            Newspaper_State=="Wyoming" ~ "West",
                            Newspaper_State=="Utah" ~ "West",
                            Newspaper_State=="Oklahoma" ~ "South",
                            Newspaper_State=="New Mexico" ~ "West",
                            Newspaper_State=="Arizona" ~ "West",
                            Newspaper_State=="Alaska" ~ "West",
                            Newspaper_State=="Hawaii" ~ "West",
                            Newspaper_State=="District of Columbia" ~ "South",
                            Newspaper_State=="Virgin Islands" ~ "Misc",
                                                     TRUE~Newspaper_State))

#delete old version
# lynch_geocoded_9.27 <- subset(lynch_geocoded_9.27, select =-Newspaper_Region2)

#write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```

### Border Designation
```{r}
lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(Border = case_when(Newspaper_State=="Maryland" ~ "Border",
                            Newspaper_State=="Delaware" ~ "Border",
                            Newspaper_State=="West Virginia" ~ "Border",
                            Newspaper_State=="Kentucky" ~ "Border",
                            Newspaper_State=="Missouri" ~ "Border",
                               .default = "Not_Border"))

# write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```


```{r}
# vibe check
lynching_data %>%
  head(10)

#check for duplicate rows
lynching_data_distinct <- lynching_data %>%
  distinct()

#all good

## Regional differences

#starter code
starter_code <- lynching_data %>% 
  select(decade, Newspaper_Region, in_state) %>% 
  group_by(Newspaper_Region) %>% 
  count(in_state)

write_csv(starter_code, "in_out_of_state_breakdown.csv")

# starter code takeaways 
# - northeast only covered one in-state lynching but reported on 222 out of state ones
# - north central region had overwhelmingly the most out of state lynching coverage, which make sense because these states are close to the south in proximity, and therefore it makes sense to cover things, but 1384 out of state vs. 55 in state is crazy

# let's clean up this dataframe

geography_starter_df <- lynching_data %>%
  clean_names() %>%
  select(newspaper_name, newspaper_state_code, state_lynch, newspaper_region, in_state, year, decade, lynching_lon, lynching_lat, news_location_lon, news_location_lat)

# overall picture of lynching coverage year-over-year

geography_starter_df %>%
  group_by(year) %>%
  summarise(total_count = n()) %>%
  arrange(desc(total_count))

# what percent of all lynchings covered in the south vs. the non-south
# what region outside of the south covered the most lynchings? how did that change over time?

# remembering how to do this
geography_starter_df %>%
  filter(newspaper_region == "South") %>%
  group_by(year) %>%
  summarise(southern_count = n()) %>%
  arrange(desc(southern_count))

# same thing just zooming out for decades -- let's use decades for this preliminary vibe check

south_count_over_time <- geography_starter_df %>%
  filter(newspaper_region == "South") %>%
  group_by(decade) %>%
  summarise(southern_count = n()) %>%
  arrange(desc(southern_count))

north_count_over_time <- geography_starter_df %>%
  filter(newspaper_region == "North Central" | newspaper_region == "Northeast") %>%
  group_by(decade) %>%
  summarise(northern_count = n()) %>%
  arrange(desc(northern_count))

west_count_over_time <- geography_starter_df %>%
  filter(newspaper_region == "West") %>%
  group_by(decade) %>%
  summarise(western_count = n()) %>%
  arrange(desc(western_count))

overall_count_over_time <- geography_starter_df %>%
  group_by(decade) %>%
  summarise(total_count = n()) %>%
  arrange(desc(total_count))

lynching_geog_over_time <- overall_count_over_time %>% left_join(south_count_over_time, by="decade") 
lynching_geog_over_time <- lynching_geog_over_time %>% left_join(north_count_over_time, by='decade')
lynching_geog_over_time <- lynching_geog_over_time %>% left_join(west_count_over_time, by='decade')

write_csv(lynching_geog_over_time, "lynching_regional_decades.csv")

# in what state did the most lynching take place?
# in what state was lynching covered the most?

coverage_occurrences_states <- geography_starter_df %>% 
  group_by(newspaper_state_code) %>% 
  summarise(coverage_count = n()) %>%
  arrange(desc(coverage_count))

lyching_occurrences_states <- geography_starter_df %>%
  group_by(state_lynch) %>%
  summarise(lynching_count = n()) %>%
  arrange(desc(lynching_count))

# the top 5 states where the most lynchings occurred were georgia, tennessee, mississippi, kentucky, alabama and texas
# the top 5 states where the most lynchings were covered were wisconsin, missouri, kansas, ohio, south dakota and north dakota

coverage_vs_lynch_occurrence <- left_join(coverage_occurrences_states, lyching_occurrences_states, by=c('newspaper_state_code'='state_lynch'))

write_csv(coverage_vs_lynch_occurrence, "coverage_vs_lynch_occurrence.csv")

```


## Week 2 Analysis

## Checking Group #1's work (lynchings in vs. out of state)


```{r pressure, echo=FALSE}

# read in new data

lynch_updated <- read_csv("../data/lynch_geocoded_10.8.csv")

# CHECK: vibe check for data

lynch_updated %>%
  group_by(in_state) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# ANSWER: overall, there were 2574 lynchings covered from out of state and 212 that were covered in the state where they occurred.

# make less ugly
lynch_updated <- lynch_updated %>%
  clean_names()

state_in_out_breakdown <- lynch_updated %>%
  select(decade, newspaper_state, in_state) %>% 
  group_by(newspaper_state) %>% 
  count(in_state)

# ----

# CHECK: what state covered the most lynchings that were out of state?
out_of_state_coverage <- state_in_out_breakdown %>%
  filter(in_state == "N") %>%
  arrange(desc(n))

# ANSWER: wisconsin, ohio, kansas, minnesota, virginia and west virginia all covered 100+ out of state lynchings

# ----

# CHECK: what state covered the most lynchings that were in state?
in_state_coverage <- state_in_out_breakdown %>%
  filter(in_state == "Y") %>%
  arrange(desc(n))

# ANSWER: kentucky and maryland covered the most lynchings that were in their own states
# ANSWER: tennessee covered 5 total lynchings, despite being a big state that popped out (just anecdotally) during our geocoding

# ----

# CHECK: Team 1's second question: What states were featured the most in out-of-state coverage?

states_df <- lynch_updated %>%
  select(decade, newspaper_name, newspaper_state_code, state_lynch, in_state, border, total_words) 

oos_coverage <- states_df %>%
  filter(in_state == "N") %>%
  group_by(state_lynch) %>%
  count(in_state)

# ANSWER: lynchings in alabama, georgia, kentucky, louisiana, mississippi, missouri, tennessee and texas were most covered in other states

# ----

# CHECK: Were any newspapers covering a large proportion of out-of-state lynchings?

newspapers_oos <- states_df %>%
  filter(in_state == "N") %>%
  group_by(newspaper_name) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

# The daily worker, The Birmingham age-herald, River Falls journal, The Topeka state journal, The daily dispatch, The Salt Lake herald, The Seattle post-intelligencer, The sun, The news & observer, Grant County herald, The morning news, The Hope pioneer, The Manitowoc pilot, Waterbury evening Democrat, Wausau pilot	all covered ** 20+ ** out of state lynchings

# prof's initial question
# What patterns do you see with states and years when focusing on in-state versus out-of-state coverage? Do the patterns change much over time?

# Team 1's first question: What percent of coverage was in-state vs. out of state in each decade (1880s-1920s), are there any patterns in coverage?

states_with_years <- lynch_updated %>%
  select(decade, newspaper_state_code, state_lynch, in_state, newspaper_name)

# doing this the convoluted way just for ease 

is <- states_with_years %>%
  filter(in_state == "Y") %>%
  group_by(decade) %>%
  summarise(in_state = n())
  
oos <- states_with_years %>%
  filter(in_state == "N") %>%
  group_by(decade) %>%
  summarise(out_of_state = n())

coverage_by_decade <- is %>% left_join(oos, by='decade')

# newspapers covered the most lynchings in the 1890s and 1900s and the in state vs. out-of-state proportions are insane

coverage_by_decade <- coverage_by_decade %>%
  mutate(pct_in_state = percent(in_state/(out_of_state + in_state)), pct_out_of_state = percent(out_of_state/(out_of_state + in_state))) 

# csvs from checking team #1 

write_csv(coverage_by_decade, "data/coverage_by_decade.csv")
write_csv(newspapers_oos, "data/newspapers_oos.csv")
write_csv(newspapers_oos, "data/newspapers_oos.csv")
write_csv(oos_coverage, "data/oos_coverage.csv")
write_csv(state_in_out_breakdown, "data/state_in_out_breakdown.csv")


```

Back to regional analysis -- new data has a region category for border states, so let's see how 


```{r}

border_states <- lynch_updated %>%
  select(decade, newspaper_region, border, in_state) %>% 
  group_by(border) %>% 
  count(in_state)

write_csv(border_states, "data/border_states.csv")

lynch_regional <- lynch_updated %>%
  select(decade, newspaper_region, border, in_state)


lynch_regional %>%
  filter(border == "Border") %>%
  group_by(decade) %>%
  summarise(coverage_count = n()) %>%
  arrange(desc(coverage_count))

lynch_regional %>%
  filter(border == "Border") %>%
  group_by(decade) %>%
  summarise(southern_count = n()) %>%
  arrange(desc(southern_count))


# basically redoing everything from last week with the most updated data

south_count_over_time <- lynch_regional %>%
  filter(newspaper_region == "South") %>%
  group_by(decade) %>%
  summarise(southern_count = n()) %>%
  arrange(desc(southern_count))

north_count_over_time <- lynch_regional %>%
  filter(newspaper_region == "North Central" | newspaper_region == "Northeast") %>%
  group_by(decade) %>%
  summarise(northern_count = n()) %>%
  arrange(desc(northern_count))

west_count_over_time <- lynch_regional %>%
  filter(newspaper_region == "West") %>%
  group_by(decade) %>%
  summarise(western_count = n()) %>%
  arrange(desc(western_count))

overall_count_over_time <- lynch_regional %>%
  group_by(decade) %>%
  summarise(total_count = n()) %>%
  arrange(desc(total_count))

border_count_over_time <- lynch_regional %>%
  filter(border == "Border") %>%
  group_by(decade) %>%
  summarise(border_count = n()) %>%
  arrange(desc(border_count))

lynching_geog_over_time <- overall_count_over_time %>% left_join(south_count_over_time, by="decade") 
lynching_geog_over_time <- lynching_geog_over_time %>% left_join(north_count_over_time, by='decade')
final_updated_geog <- lynching_geog_over_time %>% left_join(west_count_over_time, by='decade')

write_csv(final_updated_geog, "data/regional_analysis_updated.csv")

write_csv(border_count_over_time, "data/border_decades.csv")

border_decade_in_state <- lynch_regional %>%
  filter(border == "Border") %>%
  group_by(in_state) %>%
  summarise(count = n())

write_csv(border_decade_in_state, "data/border_decade_in_state.csv")

# which border states covered lynchings the most

border_state_coverage <- lynch_updated %>%
  select(decade, newspaper_state_code, state_lynch, newspaper_region, border, in_state) %>%
  filter(border == "Border")


```

## State news vs Tolnay
```{r}

# coverage_by_decade has percent by decade of in-state vs. out of state lynching coverage

# states_df has newspaper_name, newspaper_state_code, state_lynch, in_state, border, total_words

coverage_by_decade

# what newspapers had the highest 

states_df %>%
  filter(in_state == "Y") %>%
  group_by(decade, newspaper_name) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

lynch_updated %>%
  group_by(state_lynch) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# newspapers had a shockingly low amount of coverage for lynchings in their state -- the highest number of in-state lynchings covered in a single decade for any paper was 4, according to the code block above

# dataframe for other newspapers that were in high-lynching states but covered the most out of state lynchings total
# need newspaper / out of state / in state coverage for GA, MS, AL, TN

# let's start with georgia

georgia_coverage <- states_df %>%
  filter(newspaper_state_code == "GA")

georgia_coverage %>%
  group_by(in_state) %>%
  summarise(georgia_coverage_count = n())

georgia_coverage %>%
  group_by(newspaper_name) %>%
  count(in_state)

# what about mississippi 

# quick check
# states_df %>%
#  filter(state_lynch == "MS")

mississippi_coverage <- states_df %>%
  filter(newspaper_state_code == "MS")

mississippi_coverage %>%
  group_by(in_state) %>%
  summarise(mississippi_coverage_count = n())

mississippi_coverage %>%
  group_by(newspaper_name) %>%
  count(in_state)

# tennessee 

tennessee_coverage <- states_df %>%
  filter(newspaper_state_code == "TN")

tennessee_coverage %>%
  group_by(in_state) %>%
  summarise(tennessee_coverage_count = n())

tennessee_coverage %>%
  group_by(newspaper_name) %>%
  count(in_state)

# alabama

alabama_coverage <- states_df %>%
  filter(newspaper_state_code == "AL")

alabama_coverage %>%
  group_by(in_state) %>%
  summarise(alabama_coverage_count = n())

alabama_coverage %>%
  group_by(newspaper_name) %>%
  count(in_state)

# for graphic

graphic <- states_df %>%
  group_by(newspaper_state_code, in_state) %>%
  summarise(count = n()) %>%
  arrange(newspaper_state_code)

write_csv(graphic, "team_3_graphic.csv")

word_averages <- states_df %>%
  na.omit(total_words) %>%
  group_by(newspaper_state_code) %>%
  summarise(average_word_count = mean(total_words)) %>%
  arrange(average_word_count)

# TN, SC and MS were all states in the bottom 10 for average word count for a given article

# rechecking numbers with new data
# states_df %>%
#   group_by(border) %>%
#   summarise(count = n())

border_states <- states_df %>%
  filter(border == "Border")

border_states %>%
  na.omit(total_words) %>%
  group_by(newspaper_state_code) %>%
  summarise(median_word_count = median(total_words)) %>%
  arrange(median_word_count)

non_border_median_words <- states_df %>%
  filter(border == "Not_Border") %>%
  na.omit(total_words) %>%
  group_by(newspaper_state_code) %>%
  summarise(median_word_count = median(total_words)) %>%
  arrange(median_word_count)
  
border_states %>%
  group_by(newspaper_state_code) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

border_states %>%
  group_by(newspaper_state_code, decade) %>%
  count(in_state) 

yearly_lynching_in_state_out_of_state <- lynch_updated %>%
  group_by(year, in_state) %>%
  summarise(count = n()) %>%
  arrange(year)

write_csv(yearly_lynching_in_state_out_of_state, "yearly_lynching.csv")

```

## Tolnay
```{r}

# updating with tolnay/beck data to make comparisons


tolnay_beck <- read.csv("../data/bailey_beck_lynching_list_8_1_2022.csv") %>%
  as.data.frame()

tolnay_beck <- janitor::clean_names(tolnay_beck)

# let's make a dataframe of just the lynchings in the states we're interested in for this circumstance -- for later analysis

al_ga_ms_tolnay_back <- tolnay_beck %>%
  filter(lynch_state == "GA" | lynch_state == "MS" | lynch_state == "AL")

tolnay_georgia <- al_ga_ms_tolnay_back %>%
  filter(lynch_state == "GA" & year < 1929 & year >= 1880 & status == "Lynching")

#wells comment:
#we have AT LEAST 953 Georgia newspaper articles that begin 1/12/1881
#any claims of erasure will have to follow 1/12/1881


# prof says: add some details from the Tolnay-Beck data to look at all known lynchings in Georgia, total lynchings, line that up with AC coverage and any GA newspaper coverage and illustrate the gaps.

# to do this, we will:
#   - compare to georgia_coverage
#   - compare to georgia_coverage when filtered for just Atlanta Constitution

lynch_updated <- lynch_updated %>%
  mutate(date = as.Date(date, "%m/%d/%Y")) 

new_georgia_coverage <- lynch_updated %>%
  filter(newspaper_state_code == "GA") %>%
  select(decade, date, newspaper_name, newspaper_state_code, state_lynch, in_state, border, total_words, file_id, url)

new_georgia_coverage <- new_georgia_coverage %>%
  dplyr::mutate(year = lubridate::year(date), 
                month = lubridate::month(date), 
                day = lubridate::day(date))

new_georgia_coverage %>%
  group_by(newspaper_name) %>%
  summarise(count = n())

new_georgia_coverage %>%
  filter(in_state == "Y") %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(year)

tolnay_georgia %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

tolnay_georgia %>%
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

tolnay_georgia %>%
  filter(year > 1887) %>%
  filter(year < 1900)

new_georgia_coverage %>%
  filter(in_state == "N") %>%
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(decade)

new_georgia_coverage %>%
  filter(in_state == "N" & newspaper_name == "The Atlanta constitution") %>%
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(decade)

new_georgia_coverage %>%
  filter(newspaper_name == "The Atlanta constitution" & in_state == "Y") %>%
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(desc(count))
  
new_georgia_coverage %>%
  filter(newspaper_name == "The morning news" & in_state == "Y") %>%
  group_by(decade) %>%
  summarise(count = n())

```

```{r}

tolnay_ms <-  al_ga_ms_tolnay_back %>%
  filter(lynch_state == "MS" & year < 1929 & year >= 1880 & status == "Lynching")

new_mississippi_coverage <- lynch_updated %>%
  filter(newspaper_state_code == "MS") %>%
  select(decade, year, newspaper_name, newspaper_state_code, state_lynch, in_state, border, total_words)

new_mississippi_coverage %>%
  group_by(newspaper_name) %>%
  summarise(count = n())

new_mississippi_coverage %>%
  filter(in_state == "Y") %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(year)

new_mississippi_coverage %>%
  filter(in_state == "N") %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(year)

# mississippi newspapers 

lynch_updated <- lynch_updated %>%
  mutate(date = as.Date(date, "%m/%d/%Y")) 

# dataframe for states to leave
median_word_count <- lynch_updated %>%
  na.omit(total_words) %>%
  group_by(newspaper_state_code) %>%
  summarise(median_word_count = median(total_words))

write_csv(median_word_count, "median_word_count.csv")

new_mississippi_coverage %>%
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(desc(decade))

tolnay_ms %>%
  
  group_by(decade) %>%
  summarise(count = n()) %>%
  arrange(desc(decade))

tolnay_ms %>%
  count()

new_mississippi_coverage %>%
  filter(in_state == "N") %>%
  group_by(newspaper_name) %>%
  summarise(count = n())

new_mississippi_coverage %>%
  filter(in_state == "Y") %>%
  group_by(newspaper_name) %>%
  summarise(count = n())

new_mississippi_coverage %>%
  filter(newspaper_name == "Macon beacon") 

tolnay_ms %>%
  filter(decade == 1890)


```

# Memo 6

```{r}

lynch_updated %>%
  filter(state_lynch == "GA" & year == 1896) 

new_georgia_coverage %>%
  filter(year == 1903)

tolnay_georgia %>%
  filter(year == 1889 | year == 1890 | year == 1891)

tolnay_georgia %>%
  filter(year == 1903)

# there was a lynching in savannah that took place on 1896-07-09 and covered by the Butler Weekly Times in Missouri

# let's account for all possible names of savannah papers
# nothing

new_georgia_coverage %>%
  filter(newspaper_name == "The morning news" | newspaper_name == "Savannah morning news" | newspaper_name == "The Savannah morning news.") %>%
  filter(year == 1896)

# any other georgia newspapers?
new_georgia_coverage %>%
  filter(year == 1896)
#nope lol


new_mississippi_coverage %>%
  filter(newspaper_name == "Warren sheaf")

```


### Wells matching GA news and GA Tolnay

```{r}
#How many GA papers that we coded could have covered Tolnay-Beck listed lynchings
ga_tolnay <- tolnay_beck %>% 
  filter(lynch_state =="GA") %>% 
  mutate(date = paste(month,day,year, sep = "/")) %>% 
  mutate(tolnay_date = as.Date(date, "%m/%d/%Y")) %>% 
  select(status, tolnay_date, year, month, day, name, alt_name_1, lynch_county, lynch_state, method_of_death, accusation)
#685 from 1865-2001

ga_news <- lynch_updated %>% 
   filter(newspaper_state_code == "GA") %>%
   mutate(date = as.Date(date, "%m/%d/%Y")) %>% 
   mutate(year = lubridate::year(date), 
                month = lubridate::month(date), 
                day = lubridate::day(date)) %>% 
  select(date, newspaper_name, newspaper_state_code, year, month, day, decade, city_lynch, state_lynch, in_state, border, total_words, file_id, url)
#66 obs 1881-1920


# Create a sequence of dates for 15 days after date1
ga_news$date_seq <- lapply(ga_news$date, function(x) seq(as.Date(x), by = "day", length.out = 16))

# Unnest the data frame
library(tidyr)
ga_news <- unnest(ga_news, cols = c(date_seq))

ga_tolnay_news <- ga_tolnay %>% 
  inner_join(ga_news, by=c("tolnay_date"="date_seq")) %>% 
  rename(city_newspaper_report = city_lynch, tolnay_year = year.x, tolnay_month = month.x, tolnay_day = day.x, news_year = year.y, news_month = month.y, news_day = day.y, news_date = date) %>% 
  select(tolnay_year, tolnay_date, news_date, name, lynch_county, newspaper_name, news_date, news_day, city_newspaper_report, state_lynch, total_words, file_id, url, alt_name_1, method_of_death, accusation, decade) %>% 
  filter(state_lynch =="GA") 

#3 cases where GA papers covered lynchings on the Tolnay list
#My broader join showed 20 obs where GA newspapers match the Tolnay List by year and month. See below


#Notes from earlier method

# #This is sort of an ugly match. Just year and month. A better would be to match 
# ga_tolnay_news <- ga_tolnay %>% 
#   inner_join(ga_news, by=c("year", "month")) %>% 
#   rename(city_newspaper_report = city_lynch, tolnay_day = day.x, news_day = day.y) %>% 
#   select(year, month, tolnay_day, name, lynch_county, newspaper_name, date, news_day, city_newspaper_report, state_lynch, total_words, file_id, url, alt_name_1, method_of_death, accusation, decade) %>% 
#   filter(state_lynch =="GA") 

#20 obs where GA newspapers match the Tolnay List by year and month. Further filtering needed

#filter so the news follows tolnay
#ga_tolnay_news <- ga_tolnay_news[ga_tolnay_news$news_day <= ga_tolnay_news$tolnay_day, ]
#6 cases where GA papers could have covered a lynching listed in tolnay and beck  
```


```{r}
#How many GA papers that we coded could have covered Tolnay-Beck listed lynchings
ga_tolnay <- tolnay_beck %>% 
  filter(lynch_state =="GA") %>% 
  select(status, year, month, day, name, alt_name_1, lynch_county, lynch_state, method_of_death, accusation)
#685 from 1865-2001

ga_news <- lynch_updated %>% 
   filter(newspaper_state_code == "GA") %>%
   mutate(date = as.Date(date, "%m/%d/%Y")) %>% 
   mutate(year = lubridate::year(date), 
                month = lubridate::month(date), 
                day = lubridate::day(date)) %>% 
  select(decade, date, newspaper_name, newspaper_state_code, year, month, day, city_lynch, state_lynch, in_state, border, total_words, file_id, url)
#66 obs 1881-1920

ga_tolnay_news <- ga_tolnay %>% 
  inner_join(ga_news, by=c("year", "month")) %>% 
  rename(city_newspaper_report = city_lynch, tolnay_day = day.x, news_day = day.y) %>% 
  select(year, month, tolnay_day, name, lynch_county, newspaper_name, date, news_day, city_newspaper_report, state_lynch, total_words, file_id, url, alt_name_1, method_of_death, accusation, decade) %>% 
  filter(state_lynch =="GA") 
#20 obs 

ga_tolnay_news <- ga_tolnay_news[ga_tolnay_news$news_day <= ga_tolnay_news$tolnay_day, ]
#6 cases where GA papers could have covered a lynching listed in tolnay and beck  



ga_tolnay_news


```


```{r}

bigram_lynch_1890s <- read_csv("../output/1890s_lynch_bigram_count.csv")
trigram_lynch_1890s <- read_csv("../output/1890s_lynch_trigram_count.csv")

bigram_lynch_1890s <- bigram_lynch_1890s %>%
  filter(n > 5)

trigram_lynch_1890s <- trigram_lynch_1890s %>%
  filter(n > 5)

bigram_lynch_1890s %>%
  filter(str_detect(word1, 'lynch') | str_detect(word2, 'lynch'))

bigram_lynch_1890s %>%
  filter(str_detect(word1, 'negro') | str_detect(word2, 'negro')) 

trigram_lynch_1890s %>%
  filter(str_detect(word1, 'lynch') | str_detect(word2, 'lynch') | str_detect(word3, 'lynch'))

trigram_lynch_1890s %>%
  filter(str_detect(word1, 'negro') | str_detect(word2, 'negro') | str_detect(word3, 'negro'))

trigram_lynch_1890s %>%
  filter(str_detect(word1, 'mob') | str_detect(word2, 'mob') | str_detect(word3, 'mob'))

```









