#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
jackindex_geo <- read_csv("../data/extracted_articles_aug25.csv")
jackindex_geo <- separate(data = jackindex_geo, col = newspaper_name, into = c("newspaper_name1","city"), sep = "[(]", extra ="merge", fill = "right")
jackindex_geo <- separate(data = jackindex_geo, col = city, into = c("city1","state"), sep = ",", extra ="merge", fill = "right")
jackindex_geo <- separate(data = jackindex_geo, col = city1, into = c("city1","crap"), sep = "\\[")
#removes ...)
jackindex_geo$city1 <- gsub("\\.\\.\\.)", "", jackindex_geo$city1)
jackindex_geo <- jackindex_geo %>%
mutate(news_address = paste(city1, newspaper_state, sep=", "))
#Import geocoded newspapers
jackindex_geo <- read.csv("../output/geocoded_newspapers_sept4.csv")
#import geocoded articles from class
googlesheets4::gs4_deauth()
articles <- read_sheet("https://docs.google.com/spreadsheets/d/1zDWMbuoTHVtiJDrrJ9mDfBTp-VxNFTmMHiGcGA-UvjE/edit?usp=sharing") %>%
as.data.frame()
#Sort of a bullshit workaround to deal with the university's Google: https://stackoverflow.com/questions/61356212/client-doesnt-have-sufficient-permission
articles$file_id2 <- as.integer(articles$file_id)
joined <- jackindex_geo %>%
inner_join(articles, by=c("file_id"="file_id2"))
#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")
#prepare new locations
joined <- joined %>%
rename(city_lynch1 = "City, town where lynching event took place", state_lynch1 = "State where lynching event took place", city_lynch2 = "Second Article: City, town of lynching event", state_lynch2 = "Second Article: State of lynching event", city_lynch3 =  "Third Article: City, town of lynching event", state_lynch3 = "Third Article: State of lynching event")
joined <- joined %>%
mutate(lynch_address1 = paste(city_lynch1, state_lynch1, sep=", ")) %>%
mutate(lynch_address2 = paste(city_lynch2, state_lynch2, sep=", ")) %>%
mutate(lynch_address3 = paste(city_lynch3, state_lynch3, sep=", "))
joined <- joined %>%
select(file_id, newspaper_name1, news_address, news_location.lon, news_location.lat, city1, newspaper_state, date, year, month, day, page, URL, lynch_address1, lynch_address2, lynch_address3, city_lynch1, state_lynch1, city_lynch2, state_lynch2, city_lynch3, state_lynch3, `Comments or notes?`,  index, sn)
#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")
#rename newspaper_state to Postal code
joined$newspaper_state_code <- state.abb[match(joined$newspaper_state, state.name)]
#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")
joined <- joined %>%
mutate(lynching1 = geocode(lynch_address1)) %>%
mutate(lynching2 = geocode(lynch_address2)) %>%
mutate(lynching3 = geocode(lynch_address3))
joined1 <- read.csv ("../output/geocoded_TEST2_joined_sept15.csv" )
#Newspaper state abbreviation
joined1$newspaper_state_code <- state.abb[match(joined1$newspaper_state, state.name)]
df1 <- joined1 %>%
select(file_id, newspaper_name1, news_address, news_location.lon, news_location.lat, city1, newspaper_state_code, date, year, page, URL, lynch_address1, city_lynch1, state_lynch1, lynching1.lon, lynching1.lat,  Comments.or.notes.,  index, sn) %>%
rename(lynch_address=lynch_address1, city_lynch=city_lynch1, state_lynch=state_lynch1, lynching.lon=lynching1.lon, lynching.lat=lynching1.lat)
df2 <- joined1 %>%
select(file_id, newspaper_name1, news_address, news_location.lon, news_location.lat, city1, newspaper_state_code, date, year, page, URL, lynch_address2, city_lynch2, state_lynch2, lynching2.lon, lynching2.lat, Comments.or.notes., index, sn) %>%   rename(lynch_address=lynch_address2, city_lynch=city_lynch2, state_lynch=state_lynch2, lynching.lon=lynching2.lon, lynching.lat=lynching2.lat) %>%
drop_na(city_lynch)
df3 <- joined1 %>%
select(file_id, newspaper_name1, news_address, news_location.lon, news_location.lat, city1, newspaper_state_code, date, year, page, URL, lynch_address3, city_lynch3, state_lynch3, lynching3.lon, lynching3.lat, Comments.or.notes.,  index, sn) %>%   rename(lynch_address=lynch_address3, city_lynch=city_lynch3, state_lynch=state_lynch3, lynching.lon=lynching3.lon, lynching.lat=lynching3.lat) %>%
drop_na(city_lynch)
lynch_geocoded_9.16 <- rbind(df1, df2, df3)
# write.csv(lynch_geocoded_9.16, "../output/lynch_geocoded_9.16.csv")
#df10 <- read.csv("../output/lynch_geocoded_9.16.csv")
lynch_geocoded_9.16$meters <- distVincentySphere(p1 = lynch_geocoded_9.16[,c('news_location.lon', 'news_location.lat')], p2 = lynch_geocoded_9.16[,c('lynching.lon', 'lynching.lat')])
View(lynch_geocoded_9.16)
lynch_geocoded_9.16$miles <- lynch_geocoded_9.16$meters * 0.000621371
lynch_geocoded_9.16$miles <- round(lynch_geocoded_9.16$miles)
lynch_geocoded_9.16 <- subset(lynch_geocoded_9.16, select = -meters)
View(lynch_geocoded_9.16)
lynch_geocoded_9.16 <- lynch_geocoded_9.16 %>%
mutate(in_state = case_when(
newspaper_state_code == state_lynch~ "Y", TRUE ~ "N"
))
View(lynch_geocoded_9.16)
names(lynch_geocoded_9.16)
p <- lynch_geocoded_9.16 %>%
select(newspaper_name1, newspaper_state_code, state_lynch, in_state)
View(p)
lynch_geocoded_9.16 <- read.csv("../data/lynch_geocoded_9.16.csv")
View(lynch_geocoded_9.16)
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
average(miles)
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
summarize(average(miles))
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
summarize(avg(miles))
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
summarize(mean(miles))
View(y)
glimpse(lynch_geocoded_9.16)
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
mean(miles)
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
mean(miles, na.rm=TRUE)
y <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
summarize(mean(miles, na.rm=TRUE))
names(lynch_geocoded_9.16)
m <- lynch_geocoded_9.16 %>%
select(decade, Newspaper_Region, in_state) %>%
group_by(Newspaper_Region) %>%
count(in_state)
View(m)
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
lynch_geocoded_9.16 <- read.csv("../data/lynch_geocoded_9.16.csv")
x <- lynch_geocoded_9.16 %>%
select(decade, miles, in_state) %>%
group_by(decade) %>%
count(in_state)
ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
geom_col(position = "dodge") +
theme(legend.position = "none") +
labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
y="Count of articles",
x="")
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("expss")
library(expss)
install.packages("expss")
library(expss)
tolnay_beck <- read_csv("../data/Bailey_Beck_lynching_list_8_1_2022.csv") %>%
as.data.frame()
tolnay_beck <- janitor::clean_names(tolnay_beck)
