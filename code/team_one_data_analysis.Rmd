---
title: "Geographic Analysis"
author: "Rob Wells"
date: "2023-09-20"
output: html_document
---
This notebook has two parts.

The BUILDING THE DATA:
Will clean and geocode the cities and states of the newspapers. 
And then it will geocode the cities and states of the crimes.
And then it will measure:
1) Whether the newspaper was reporting on an in-state or out-of-state event
2) The distance from the newspaper's city to the city of the lynching


The ANALYSIS
--Looks at In state / out of state coverage
--Distance over time
--Southern vs other regions

```{r}
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("expss")
library(expss)
```
# Analysis
```{r}
lynch_geocoded_9.16 <- read.csv("../data/lynch_geocoded_9.16.csv")

```

# Basic Analysis, Duplicated Entries
```{r}
## Pct of Newspapers in state vs out of state
 lynch_geocoded_9.16 %>% 
  count(in_state) %>% 
  mutate(pct = round(n/3292,2))


# in_state
# N	3068	0.93		
# Y	223	0.07	

summary(lynch_geocoded_9.16$miles)
#Newspapers, on average, were 878 miles away from a lynching event during the whole time period

duplicated_entries <- lynch_geocoded_9.16 %>% 
  group_by(file_id) %>% 
  count(lynch_address) %>% 
  filter(n > 1)

# Repetitions: 
write_sheet(duplicated_entries, "https://docs.google.com/spreadsheets/d/1mt-K372GEtjE_v0qeiX-57MlnAD-9tT5f4AZr4NxZnY/edit#gid=0")


```

## In State v Out of State by Decade
```{r}

x <- lynch_geocoded_9.16 %>% 
  select(decade, miles, in_state) %>% 
  group_by(decade) %>% 
  count(in_state)

  ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
    geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
       subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
       caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
       y="Count of articles",
       x="")

  
cleaned_articles <- lynch_geocoded_9.16 %>% 
  distinct(file_id, lynch_address, .keep_all = TRUE) %>% 
  mutate(location = case_when(
    newspaper_state_code == state_lynch ~ "in_state",
    TRUE~"out_of_state"
  ))
  
decade_data <- cleaned_articles %>% 
  group_by(decade, location) %>% 
  count(.) %>% 
  pivot_wider(names_from = location, values_from = n) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>% 
  mutate(sum_articles = out_of_state + in_state) %>% 
  mutate(percent_oos = round(out_of_state/sum_articles*100, 2)) %>% 
  mutate(percent_is = round(in_state/sum_articles*100, 2))

write_sheet(decade_data, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0")

state_groupings <- cleaned_articles %>%
  group_by(newspaper_state_code, location) %>% 
  count(.) %>% 
  pivot_wider(names_from = location, values_from = n) %>% 
  mutate_if(is.numeric, ~replace(., is.na(.), 0)) %>% 
  mutate(sum_articles = out_of_state + in_state) %>% 
  mutate(percent_oos = round(out_of_state/sum_articles*100, 2)) %>% 
  mutate(percent_is = round(in_state/sum_articles*100, 2))

write_sheet(state_groupings, "https://docs.google.com/spreadsheets/d/1udiQCGe-Qou-WlAiBYJgW23AccOx-_4pNHKNjzIreXA/edit#gid=0")

```