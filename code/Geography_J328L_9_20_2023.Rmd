---
title: "Geographic Analysis"
author: "Rob Wells"
date: "2023-09-20"
output: html_document
---
This notebook has two parts.

The BUILDING THE DATA:
Will clean and geocode the cities and states of the newspapers. 
And then it will geocode the cities and states of the crimes.
And then it will measure:
1) Whether the newspaper was reporting on an in-state or out-of-state event
2) The distance from the newspaper's city to the city of the lynching


The ANALYSIS
--Looks at In state / out of state coverage
--Distance over time
--Southern vs other regions

```{r}
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
```
#Building the Data

## Import newspaper index, clean
```{r}
jackindex_geo <- read_csv("../data/extracted_articles_aug25.csv")

jackindex_geo <- separate(data = jackindex_geo, col = newspaper_name, into = c("newspaper_name1","city"), sep = "[(]", extra ="merge", fill = "right") 

jackindex_geo <- separate(data = jackindex_geo, col = city, into = c("city1","state"), sep = ",", extra ="merge", fill = "right") 

jackindex_geo <- separate(data = jackindex_geo, col = city1, into = c("city1","crap"), sep = "\\[")

#removes ...)
jackindex_geo$city1 <- gsub("\\.\\.\\.)", "", jackindex_geo$city1)

jackindex_geo <- jackindex_geo %>% 
  mutate(news_address = paste(city1, newspaper_state, sep=", "))

```

```{r}
bf <- jackindex_geo %>% 
  count(file_id2, file_id) %>% 
  count(file_id) %>% 
  arrange(desc(n))


```

## Geocode
```{r}


#do this once, skip to next chunk to import results
# jackindex_geo <- jackindex_geo %>% 
#   mutate(news_location = geocode(news_address))
# 
# jackindex_geo <- jackindex_geo %>% as.data.frame()
# 
# write.csv(jackindex_geo, "../output/geocoded_newspapers_sept4.csv")
```

```{r}
#Import geocoded newspapers
jackindex_geo <- read.csv("../output/geocoded_newspapers_sept4.csv")

#import geocoded articles from class

googlesheets4::gs4_deauth()
articles <- read_sheet("https://docs.google.com/spreadsheets/d/1zDWMbuoTHVtiJDrrJ9mDfBTp-VxNFTmMHiGcGA-UvjE/edit?usp=sharing") %>% 
  as.data.frame()
#Sort of a bullshit workaround to deal with the university's Google: https://stackoverflow.com/questions/61356212/client-doesnt-have-sufficient-permission

articles$file_id2 <- as.integer(articles$file_id)

joined <- jackindex_geo %>% 
  inner_join(articles, by=c("file_id"="file_id2"))

#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")
```


```{r}
#prepare new locations
joined <- joined %>% 
  rename(city_lynch1 = "City, town where lynching event took place", state_lynch1 = "State where lynching event took place", city_lynch2 = "Second Article: City, town of lynching event", state_lynch2 = "Second Article: State of lynching event", city_lynch3 =  "Third Article: City, town of lynching event", state_lynch3 = "Third Article: State of lynching event")

joined <- joined %>% 
  mutate(lynch_address1 = paste(city_lynch1, state_lynch1, sep=", ")) %>% 
  mutate(lynch_address2 = paste(city_lynch2, state_lynch2, sep=", ")) %>%
  mutate(lynch_address3 = paste(city_lynch3, state_lynch3, sep=", ")) 

joined <- joined %>% 
  select(file_id, newspaper_name1, news_address, news_location.lon, news_location.lat, city1, newspaper_state, date, year, month, day, page, URL, lynch_address1, lynch_address2, lynch_address3, city_lynch1, state_lynch1, city_lynch2, state_lynch2, city_lynch3, state_lynch3, `Comments or notes?`,  index, sn)
#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")

#rename newspaper_state to Postal code
joined$newspaper_state_code <- state.abb[match(joined$newspaper_state, state.name)]

#write_csv(joined, "../output/geocoded_TEST_joined_sept15.csv")
```


```{r}
#check totals
x <- joined %>% 
  select(newspaper_state_code) %>% 
  group_by(newspaper_state_code) %>% 
  count(newspaper_state_code) %>%
  rename(news_state_total =n)

y <- joined %>% 
  select(state_lynch1) %>% 
  group_by(state_lynch1) %>% 
  count(state_lynch1) %>% 
  rename(state_lynch_total =n)

states_compare <- x %>% 
  inner_join(y, by=c("newspaper_state_code" = "state_lynch1"))

# write.csv(states_compare, "../output/states_compared_TEST_sept15.csv" )

```

```{r}

df1 <- joined %>% 
  select(file_id, newspaper_name1, news_address, news_location_lon, news_location_lat, city1, newspaper_state_code, date, year, page, url, lynch_address1, city_lynch1, state_lynch1, comments_or_notes, index, sn) %>% 
  rename(lynch_address=lynch_address1, city_lynch=city_lynch1, state_lynch=state_lynch1)

df2 <- joined %>%
    select(file_id, newspaper_name1, news_address, news_location_lon, news_location_lat, city1, newspaper_state_code, date, year, page, url, lynch_address2, city_lynch2, state_lynch2, comments_or_notes, index, sn) %>%   rename(lynch_address=lynch_address2, city_lynch=city_lynch2, state_lynch=state_lynch2) %>% 
    drop_na(city_lynch)

df3 <- joined %>% 
      select(file_id, newspaper_name1, news_address, news_location_lon, news_location_lat, city1, newspaper_state_code, date, year, page, url, lynch_address3, city_lynch3, state_lynch3, comments_or_notes, index, sn) %>%   rename(lynch_address=lynch_address3, city_lynch=city_lynch3, state_lynch=state_lynch3) %>% 
    drop_na(city_lynch)

lynch_geocoded_9.27 <- rbind(df1, df2, df3)


```

### Cut duplicates
```{r}

#cuts 1115 duplicates from 3188 to 2073
# df3 <- unique(  lynch_geocoded_9.16[ , c('file_id','newspaper_name1','lynch_address','date',  "news_address", "news_location.lon", "news_location.lat",   "city1", "newspaper_state_code","year","page", "URL", "lynch_address", "city_lynch", "state_lynch", "lynching.lon","lynching.lat",              "sn","news_location","lynch_location","miles","in_state", "decade","Newspaper_State","Newspaper_Region" ) ] )

#cuts 1566 duplicates from 4453 to 2887
df4 <- unique(  lynch_geocoded_9.27[ , c('file_id','newspaper_name1','lynch_address','date',  "news_address", "news_location_lon", "news_location_lat",   "city1", "newspaper_state_code","year","page", "url", "lynch_address", "city_lynch", "state_lynch", "sn") ] )

df4 <- subset(df4, select =-lynch_address.1)

lynch_geocoded_9.27 <- df4 %>% 
  rename(newspaper_city = city1, newspaper_name = newspaper_name1)
lynch_geocoded_9.27 <- lynch_geocoded_9.27  %>% 
  rename(newspaper_name = newspaper_name1)
#write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")

```



## Calculate Distance
```{r}
# install.packages("geosphere")
# library(geosphere)


# Calculate the distance
lynch_geocoded_9.16$meters <- distVincentySphere(p1 = lynch_geocoded_9.16[,c('news_location.lon', 'news_location.lat')], p2 = lynch_geocoded_9.16[,c('lynching.lon', 'lynching.lat')])

# The distance is in meters, convert to miles
lynch_geocoded_9.16$miles <- lynch_geocoded_9.16$meters * 0.000621371

lynch_geocoded_9.16$miles <- round(lynch_geocoded_9.16$miles)

lynch_geocoded_9.16 <- subset(lynch_geocoded_9.16, select = -meters) 


#write.csv(lynch_geocoded_9.16, "../output/lynch_geocoded_9.16.csv")

```

# Geocode
```{r}

lynch_geocoded_9.27 <- lynch_geocoded_9.27  %>%
  mutate(lynching = geocode(lynch_address)) 

write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
df5 <- lynch_geocoded_9.27
#df5 <- read.csv("../data/lynch_geocoded_9.27.csv")
```


## Calculate Distance
```{r}
# install.packages("geosphere")
# library(geosphere)


# Calculate the distance
df5$meters <- distVincentySphere(p1 = df5[,c('news_location_lon', 'news_location_lat')], p2 = df5[,c('lynching.lon', 'lynching.lat')])

# The distance is in meters, convert to miles
df5$miles <- df5$meters * 0.000621371

df5$miles <- round(df5$miles)

df5 <- subset(df5, select = -meters) 

lynch_geocoded_9.27 <- df5
#write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")

```

## In v Out State
```{r}
#in vs out of state

lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(in_state = case_when(
    newspaper_state_code == state_lynch~ "Y", TRUE ~ "N"
  ))

#write.csv(lynch_geocoded_9.16, "../output/lynch_geocoded_9.16.csv")

```
## Regional classification for newspaper

```{r}
#Classification based on https://www.census.gov/programs-surveys/economic-census/guidance-geographies/levels.html#par_textimage_34
lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(Newspaper_Region=Newspaper_State) %>% 
  mutate(Newspaper_Region = case_when(Newspaper_State=="South Carolina" ~ "South",
                           Newspaper_State=="Texas" ~ "South",
                            Newspaper_State=="Louisiana" ~ "South",
                            Newspaper_State=="Tennessee" ~ "South",
                            Newspaper_State=="Mississippi" ~ "South",
                            Newspaper_State=="Arkansas" ~ "South",
                            Newspaper_State=="Alabama" ~ "South",
                            Newspaper_State=="Georgia" ~ "South",
                            Newspaper_State=="Virginia" ~ "South",
                            Newspaper_State=="Florida" ~ "South",
                            Newspaper_State=="North Carolina" ~ "South",
                            Newspaper_State=="Maryland" ~ "South",
                            Newspaper_State=="Delaware" ~ "South",
                            Newspaper_State=="West Virginia" ~ "South",
                            Newspaper_State=="Kentucky" ~ "South",
                            Newspaper_State=="Missouri" ~ "Midwest",
                            Newspaper_State=="Maine" ~ "Northeast",
                            Newspaper_State=="New York" ~ "Northeast",
                            Newspaper_State=="New Hampshire" ~ "Northeast",
                            Newspaper_State=="Vermont" ~ "Northeast",
                            Newspaper_State=="Massachusetts" ~ "Northeast",
                            Newspaper_State=="Connecticut" ~ "Northeast",
                            Newspaper_State=="Rhode Island" ~ "Northeast",
                            Newspaper_State=="Pennsylvania" ~ "Northeast",
                            Newspaper_State=="New Jersey" ~ "Northeast",
                            Newspaper_State=="Ohio" ~ "Midwest",
                            Newspaper_State=="Indiana" ~ "Midwest",
                            Newspaper_State=="Kansas" ~ "Midwest",
                            Newspaper_State=="Michigan" ~ "Midwest",
                             Newspaper_State=="Wisconsin" ~ "Midwest",
                             Newspaper_State=="Minnesota" ~ "Midwest",
                             Newspaper_State=="Iowa" ~ "Midwest",
                             Newspaper_State=="California" ~ "West",
                             Newspaper_State=="Nevada" ~ "West",
                             Newspaper_State=="Oregon" ~ "West",
                            Newspaper_State=="Illinois" ~ "Midwest",
                            Newspaper_State=="Nebraska" ~ "Midwest",
                            Newspaper_State=="Colorado" ~ "West",
                            Newspaper_State=="North Dakota" ~ "Midwest",
                            Newspaper_State=="South Dakota" ~ "Midwest",
                            Newspaper_State=="Montana" ~ "West",
                            Newspaper_State=="Washington" ~ "West",
                            Newspaper_State=="Idaho" ~ "West",
                            Newspaper_State=="Wyoming" ~ "West",
                            Newspaper_State=="Utah" ~ "West",
                            Newspaper_State=="Oklahoma" ~ "South",
                            Newspaper_State=="New Mexico" ~ "West",
                            Newspaper_State=="Arizona" ~ "West",
                            Newspaper_State=="Alaska" ~ "West",
                            Newspaper_State=="Hawaii" ~ "West",
                            Newspaper_State=="District of Columbia" ~ "South",
                            Newspaper_State=="Virgin Islands" ~ "Misc",
                                                     TRUE~Newspaper_State))

#delete old version
# lynch_geocoded_9.27 <- subset(lynch_geocoded_9.27, select =-Newspaper_Region2)


#write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```

### Border Designation
```{r}
lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
  mutate(Border = case_when(Newspaper_State=="Maryland" ~ "Border",
                            Newspaper_State=="Delaware" ~ "Border",
                            Newspaper_State=="West Virginia" ~ "Border",
                            Newspaper_State=="Kentucky" ~ "Border",
                            Newspaper_State=="Missouri" ~ "Border",
                               .default = "Not_Border"))

# write.csv(lynch_geocoded_9.27, "../data/lynch_geocoded_9.27.csv")
```

## Compile by decade
```{r}

lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
    mutate(decade = case_when(
      year < 1800 ~ "pre1800",
      year >= 1800 & year <=1809 ~ "1800s",
      year >= 1810 & year <=1819 ~ "1810s",
      year >= 1820 & year <=1829 ~ "1820s",
      year >= 1830 & year <=1839 ~ "1830s",
      year >= 1840 & year <=1849 ~ "1840s",
      year >= 1850 & year <=1859 ~ "1850s",
      year >= 1860 & year <=1869 ~ "1860s",
      year >= 1870 & year <=1879 ~ "1870s",
      year >= 1880 & year <=1889 ~ "1880s",
      year >= 1890 & year <=1899 ~ "1890s",
      year >= 1900 & year <=1909 ~ "1900s",
      year >= 1910 & year <=1919 ~ "1910s",
      year >= 1920 & year <=1929 ~ "1920s",
      year >= 1930 & year <=1939 ~ "1930s",
      year >= 1940 & year <=1949 ~ "1940s",
      year >= 1950 & year <=1959 ~ "1950s",
      year >= 1960 & year <=1969 ~ "1960s",
      year >= 1970 ~ "post1970s"
         ))
```

#Analysis
```{r}
lynch_geocoded_9.27 <- read.csv("../data/lynch_geocoded_9.27.csv")

```

### In vs Out of State
```{r}
## Pct of Newspapers in state vs out of state
 # lynch_geocoded_9.16 %>% 
 #  count(in_state) %>% 
 #  mutate(pct = round(n/sum(n),2))


# in_state
# N	3068	0.93		
# Y	223	0.07	

lynch_geocoded_9.27 %>% 
  count(in_state) %>% 
  mutate(pct = round(n/sum(n),2))

# in_state
# N	2675	0.93		
# Y	212	0.07

# summary(lynch_geocoded_9.16$miles)
#Newspapers, on average, were 878 miles away from a lynching event during the whole time period
summary(lynch_geocoded_9.27$miles)
#Newspapers, on average, were 909 miles away from a lynching event during the whole time period


```

## Viz the decades
```{r}

x <- lynch_geocoded_9.16 %>% 
  select(decade, miles, in_state) %>% 
  group_by(decade) %>% 
  count(in_state)

  ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
    geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
       subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
       caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
       y="Count of articles",
       x="")


```

# Fact Check - Duplicates
```{r}
fact <- lynch_geocoded_9.16 %>%
  select(file_id, lynch_address, date) %>% 
  group_by(lynch_address, file_id) %>% 
    count(lynch_address) %>% 
  arrange(desc(n))

fact
```



### Comments - analyze student comments
```{r}
comments <- lynch_geocoded_9.16 %>% 
  select(file_id, date, Comments.or.notes., URL) %>% 
  na.omit(Comments.or.notes.) %>% 
  distinct()

fact1 <- df3 %>%
  select(file_id, lynch_address, date) %>% 
  group_by(lynch_address, file_id) %>% 
    count(lynch_address) %>% 
  arrange(desc(n))
fact1


```

### Check an article entry
```{r}

df2 %>% 
   filter(file_id==8846) 

```

### Filter Comments for nolynching
```{r}

nolynch <- filter(lynch_geocoded_9.16, grepl ('no lynching', Comments.or.notes.))

nolynch <- nolynch %>% 
  select('file_id','date','Comments.or.notes.', 'newspaper_name1',"URL",'lynch_address',  "news_address", "news_location.lon", "news_location.lat",   "city1", "newspaper_state_code","year","page",  "lynch_address", "city_lynch", "state_lynch", "lynching.lon","lynching.lat",              "sn","news_location","lynch_location","miles","in_state", "decade","Newspaper_State","Newspaper_Region" ) %>% 
  distinct()

write.csv(nolynch, "../output/no_lynching_comments.csv")

```



## In State v Out of State by Decade
```{r}

x <- lynch_geocoded_9.27 %>% 
  select(decade, miles, in_state) %>% 
  group_by(decade) %>% 
  count(in_state)

  ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
    geom_col(position = "dodge") + 
  theme(legend.position = "none") +
  labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
       subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
       caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 27 2024",
       y="Count of articles",
       x="")


```


## Distance Over Time
```{r}
#starter code
y <- lynch_geocoded_9.27 %>% 
  select(decade, miles, in_state) %>% 
  group_by(decade) %>% 
  summarize(mean(miles, na.rm=TRUE))

  # ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
  #   geom_col(position = "dodge") + 
  # theme(legend.position = "none") +
  # labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
  #      subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
  #      caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
  #      y="Count of articles",
  #      x="")

```


```{r}
## Regional differences

#starter code
m <- lynch_geocoded_9.27 %>% 
  select(decade, Newspaper_Region2, in_state) %>% 
  group_by(Newspaper_Region2) %>% 
  count(in_state)

```


# Compare to all lynchings

```{r}
tolnay_beck <- read_csv("../data/Bailey_Beck_lynching_list_8_1_2022.csv") %>% 
  as.data.frame()

tolnay_beck <- janitor::clean_names(tolnay_beck)


```


#Notes

```{r}
### Regional classification
# library(datasets)
# state_info <- tibble(state_name = state.name, State = state.abb, Region = state.region) %>% 
#   as.data.frame()
# 
# lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
#   inner_join(state_info, by=c("newspaper_state_code"="State"))
# 
# lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>% 
#   rename(Newspaper_State = state_name, Newspaper_Region = Region)



```

