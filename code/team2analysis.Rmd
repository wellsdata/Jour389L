---
title: "Team 2 Analysis"
author: "Hannah Marszalek, Apurva Mahajan, Sasha Allen, Marwa Barakat"
date: "2023-09-21"
output: html_document
---

In this notebook, we are using the geocoding data to look at how the distance between the newspapers and the lynchings they reported on changed over time.

```{r}
#install.packages("here")
here::here()
library(tidyverse)
library(tidyr)
#install.packages("ggmap")
library(ggmap)
#register_google(key = "YOUR KEY HERE")
library(googlesheets4)
#install.packages("geosphere")
library(geosphere)
#install.packages("kableExtra")
library(kableExtra)
#webshot::install_phantomjs()
library(lubridate)
```

# Analysis
```{r}
lynch_geocoded_10.8 <- read.csv("../data/lynch_geocoded_10.8.csv")

```

## Distance Over Time
```{r}
#cleaning initial data
# lynch_geocoded_9.27 <- lynch_geocoded_9.27 %>%
#   distinct(file_id, lynch_address, .keep_all = TRUE)

#distance split by decade
distance_by_decade <- lynch_geocoded_10.8 %>% 
  select(decade, miles) %>% 
  group_by(decade) %>% 
  summarize(mean_miles = mean(miles, na.rm=TRUE)) %>%
  mutate(mean_miles = round(mean_miles, digits = 2)) %>%
  arrange(desc(mean_miles))

#formatted table
distance_by_decade %>%
  kbl(caption = "Average Distance of Lynching Reporting by Decade") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F, font_size = 14)

#write.csv(distance_by_decade, "~/Desktop/average_distance_by_decade.csv")
#write_sheet()

#distance grouped by newspaper title
distance_by_paper <- lynch_geocoded_10.8 %>%
  select(newspaper_name, newspaper_state_code, miles) %>%
  group_by(newspaper_name, newspaper_state_code) %>%
  filter(!is.na(newspaper_name)) %>%
  summarize(mean_miles = mean(miles, na.rm=TRUE)) %>%
  mutate(mean_miles = round(mean_miles, digits = 2)) %>%
  rename(newspaper_name = newspaper_name, newspaper_state = newspaper_state_code) %>%
  arrange(desc(mean_miles))

top_20_papers <- distance_by_paper[1:20, ]

#formatted table
top_20_papers %>%
  kbl(caption = "Newspapers with the Highest Average Lynching Reporting Distance") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F, font_size = 14)

#write.csv(distance_by_paper, "~/Desktop/average_distance_by_paper.csv")
#write.csv(top_20_papers, "~/Desktop/top_20_papers_distance.csv")

#distance group by newspaper states
distance_by_state <- lynch_geocoded_10.8 %>%
  select(newspaper_state_code, miles) %>%
  group_by(newspaper_state_code) %>%
  summarize(mean_miles = mean(miles, na.rm=TRUE)) %>%
  mutate(mean_miles = round(mean_miles, digits = 2)) %>%
  rename(state = newspaper_state_code) %>%
  arrange(desc(mean_miles))

top_10_states <- distance_by_state[1:10, ]

#formatted table
top_10_states %>%
  kbl(caption = "States with the Highest Average Lynching Reporting Distance") %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F, font_size = 14)

#write.csv(distance_by_state, "~/Desktop/average_distance_by_state.csv")
#write.csv(top_10_states, "~/Desktop/top_10_states_distance.csv")

#write.csv(distance_by_paper, "../output/average_reporting_distance_newspapers.csv")

# in_state_yn <- lynch_geocoded_9.16 %>%
#   select(decade, in_state) %>%
#   mutate(
#     yes = case_when(
#     in_state == "Y" ~ "Y",
#     TRUE ~ NA_character_
#     )) %>%
#   mutate(
#     no = case_when(
#     in_state == "N" ~ "N",
#     TRUE ~ NA_character_
#     ))

  # ggplot(x, aes(x=decade, y=n, color=in_state, fill=in_state)) +
  #   geom_col(position = "dodge") + 
  # theme(legend.position = "none") +
  # labs(title = "DRAFT FINDINGS: Little Local Coverage of Lynching",
  #      subtitle = "Local (teal) vs Out-of-State (red) Lynching Coverage",
  #      caption = "Teal bar=In-state. Red Bar=Out-of-State. Source: Library of Congress. n=3188 Graphic by Rob Wells. Sept 20 2024",
  #      y="Count of articles",
  #      x="")

```

# Wire Grouping 
```{r}
#I grouped the stories based on whether they were within 15 days of each other

#This code uses the diff function to calculate the difference between consecutive dates and checks if the difference is greater than 15. It then accumulates the results using cumsum to create a new grouping column called group.
#cumsum: Cumulative Sums, Products, and Extremes
wire_coverage2 <- lynch_geocoded_10.8 %>%
  select(newspaper_name, lynch_address, date, miles, newspaper_state_code, file_id, url) %>%
  mutate(fixed_date=mdy(date)) 

wire_coverage2 <- wire_coverage2[duplicated(wire_coverage2$lynch_address) | duplicated(wire_coverage2$lynch_address, fromLast = TRUE), ]

wire_coverage2 <- wire_coverage2 %>% 
    filter(lynch_address != "NA, NA" & lynch_address != "None, NONE")

wire_coverage2 <- wire_coverage2 %>%
  mutate(group = cumsum(c(TRUE, diff(fixed_date)>15)))%>% 
  group_by(group)

#wire_coverage2 <- wire_coverage2[duplicated(wire_coverage2$group) | duplicated(wire_coverage2$group, fromLast = TRUE), ]

filtered_wire <- wire_coverage2[duplicated(wire_coverage2[, c("lynch_address", "group")]) | duplicated(wire_coverage2[, c("lynch_address", "group")], fromLast = TRUE), ]

#This df will show you the likely groups of wire coverage
#But we have to read the files to make sure that's the case.
wire_grouped <- wire_coverage2 %>% 
  group_by(group) %>% 
  count(group) %>% 
  filter(n>=6) %>% 
  arrange(desc(n))

#For example, group 908 gathered a dozen article, and all but two were about the 1915 lynching of Leo Frank. 
#I think this might be the way to figure out wire coverage - split up the groupings by date, see of the same victim or place is named.
#files that are not part of the group can be identified and excluded in a subsequent filtering.

#Count the number of pairs
#671 pairs
wire_grouped <- wire_coverage2 %>% 
  group_by(group) %>% 
  count(group) %>% 
  filter(n>=2) %>% 
  arrange(desc(n))

#I experimented with your excellent code and dropped it down to 128 observations, which is too tight a filter. 
same_towns <- wire_coverage2[duplicated(wire_coverage2[, c("lynch_address", "group")]) | duplicated(wire_coverage2[, c("lynch_address", "group")], fromLast = TRUE), ]

#write_sheet(filtered_wire, "https://docs.google.com/spreadsheets/d/1yt78ISXWJxpqig1x2feStOdtcnjOHA8vLf46lqe6zcE/edit#gid=0", sheet = "filtered_wire_groups")

```

```{r}
new_wire_cases <- lynch_geocoded_10.8 %>%
  select(newspaper_name, lynch_address, date, miles, newspaper_state_code, state_lynch, url) %>%
  mutate(fixed_date=mdy(date)) %>%
  rename(paper_state = newspaper_state_code) %>%
  filter(lynch_address != "NA, NA" & lynch_address != "None, NONE")

new_wire_cases <- new_wire_cases[duplicated(new_wire_cases$lynch_address) | duplicated(new_wire_cases$lynch_address, fromLast = TRUE), ]

new_wire_cases <- new_wire_cases %>%
  mutate(group = cumsum(c(TRUE, diff(fixed_date)>15)))%>% 
  group_by(group)
```

```{r}
## Looking into wire coverage: isolate by date and city

wire_coverage <- lynch_geocoded_10.8 %>%
  select(newspaper_name, lynch_address, date, miles, newspaper_state_code, url) %>%
  mutate(fixed_date=mdy(date)) %>%
  mutate(month = floor_date(fixed_date, "month")) %>%
  select(-date) %>%
  rename(paper_state = newspaper_state_code) %>%
  filter(lynch_address != "NA, NA" & lynch_address != "None, NONE")

duplicates <- wire_coverage[duplicated(wire_coverage$lynch_address) | duplicated(wire_coverage$lynch_address, fromLast = TRUE), ]

check_duplicates <- duplicates %>%
  group_by(lynch_address) %>%
  count()

#write_sheet(wire_coverage, "https://docs.google.com/spreadsheets/d/1yt78ISXWJxpqig1x2feStOdtcnjOHA8vLf46lqe6zcE/edit#gid=0", sheet = "wire_coverage")

#write_sheet(duplicates, "https://docs.google.com/spreadsheets/d/1yt78ISXWJxpqig1x2feStOdtcnjOHA8vLf46lqe6zcE/edit#gid=0", sheet = "only_duplicate_cities")

city_and_date <- wire_coverage[duplicated(wire_coverage[, c("lynch_address", "month")]) | duplicated(wire_coverage[, c("lynch_address", "month")], fromLast = TRUE), ]

#write_sheet(city_and_date, "https://docs.google.com/spreadsheets/d/1yt78ISXWJxpqig1x2feStOdtcnjOHA8vLf46lqe6zcE/edit#gid=0", sheet = "duplicate_cities_and_months")

#creating a new column to indicate the cases that are potential examples of wire coverage
lynch_geocoded_10.8 <- lynch_geocoded_10.8 %>%
  mutate(wire_story = case_when(
    rownames(lynch_geocoded_10.8) %in% rownames(city_and_date) ~ "yes",
    TRUE ~ "no"
  ))

check <- lynch_geocoded_10.8 %>%
  group_by(wire_story) %>%
  count()

#counting possible total of wire coverage cases
counting_wire_cases <- lynch_geocoded_10.8 %>%
  select(newspaper_name, lynch_address, date, miles, newspaper_state_code, state_lynch, decade, total_words, Newspaper_Region) %>%
  mutate(fixed_date=mdy(date)) %>%
  mutate(month = floor_date(fixed_date, "month")) %>%
  select(-date) %>%
  rename(paper_state = newspaper_state_code) %>%
  filter(lynch_address != "NA, NA" & lynch_address != "None, NONE")

counting_wire_cases <- counting_wire_cases[duplicated(counting_wire_cases[, c("lynch_address", "month")]) | duplicated(counting_wire_cases[, c("lynch_address", "month")], fromLast = TRUE), ]

wire_newspapers <- counting_wire_cases %>%
  group_by(newspaper_name, paper_state) %>%
  summarize(mean_miles = mean(miles, na.rm=TRUE), count = n()) %>%
  filter(!is.na(newspaper_name)) %>%
  mutate(mean_miles = round(mean_miles, digits = 2))

states_wire_coverage <- wire_newspapers %>%
  group_by(paper_state) %>%
  summarize(mean_miles = mean(mean_miles, na.rm=TRUE), count = n()) %>%
  arrange(desc(count))

top_35_states_wire <- states_wire_coverage[1:35, ]

top_20_states_wire_coverage <- states_wire_coverage[1:20, ]

#Looking at article length
avg_article_length_by_decade <- counting_wire_cases %>%
  group_by(decade) %>%
  summarize(avg_length = mean(total_words, na.rm=TRUE), avg_distance = mean(miles, na.rm=TRUE)) %>%
  arrange(desc(avg_length)) %>%
  mutate(avg_length = round(avg_length, digits = 2), avg_distance = round(avg_distance, digits = 2))

avg_article_length_by_state <- counting_wire_cases %>%
  group_by(paper_state) %>%
  summarize(avg_length = mean(total_words, na.rm=TRUE), avg_distance = mean(miles, na.rm=TRUE)) %>%
  arrange(desc(avg_length)) %>%
  mutate(avg_length = round(avg_length, digits = 2), avg_distance = round(avg_distance, digits = 2))

avg_article_length_by_region <- counting_wire_cases %>%
  group_by(Newspaper_Region) %>%
  summarize(avg_length = mean(total_words, na.rm=TRUE), avg_distance = mean(miles, na.rm=TRUE)) %>%
  arrange(desc(avg_length)) %>%
  mutate(avg_length = round(avg_length, digits = 2), avg_distance = round(avg_distance, digits = 2))
```

## Attempting to make new labeling system for wire coverage
```{r}
label_counter <- 1

# Create a new column for labels and initialize it with NA
counting_wire_cases$wire_story <- NA

# Iterate through the rows
for (i in 1:nrow(counting_wire_cases)) {
  # If it's the first row, assign a new label
  if (i == 1) {
    counting_wire_cases$wire_story[i] <- label_counter
  } else {
    # Check for missing values and compare the current row with the previous row
    if (!is.na(counting_wire_cases$address[i - 1]) & !is.na(counting_wire_cases$address[i]) & !is.na(counting_wire_cases$date[i - 1]) & !is.na(counting_wire_cases$date[i]) & counting_wire_cases$address[i] == counting_wire_cases$address[i - 1] & counting_wire_cases$date[i] == counting_wire_cases$date[i - 1]) {
      # If they match, assign the same label as the previous row
      counting_wire_cases$wire_story[i] <- counting_wire_cases$wire_story[i - 1]
    } else {
      # If they don't match or there are missing values, increment the label counter and assign the new label
      label_counter <- label_counter + 1
      counting_wire_cases$wire_story[i] <- label_counter
    }
  }
}
```

## Visualizations for Reporting Distance
```{r}
distance_by_decade %>%
  ggplot() +
  geom_bar(aes(x=decade, weight=mean_miles), fill="slategray2") +
  labs(
    title="Reporting Distance by Decade\n",
    x = "\nDecade",
    y = "Average Miles\n"
  )

top_20_states_wire_coverage %>%
  ggplot() +
  geom_bar(aes(x=paper_state, weight=mean_miles), fill="slategray2") +
  labs(
    title="Average Distance for States Reporting on Out-of-State Lynching Incidents\n",
    x = "\nState",
    y = "Average Miles\n"
  )

ggplot(top_35_states_wire, aes(x = paper_state, y = mean_miles)) +
  geom_point(aes(size = count), color = "blue") +
  labs(
    x = "State",
    y = "Average Miles",
    title = "Average Distance for Wire Coverage by State"
  ) +
  theme(text = element_text(size = 9))

#Make new version of previous visualization changing the x-axis to be a timeline - so it wouldn't be broken down by state, it would be by decade. Also make sure it doesn't exclude the cases where the newspaper state is the same as the lynching state

#Idea: make new line graph with two lines: one for word length and one for distance from the lynching to see if there's an inverse relationship between word count and distance


```
